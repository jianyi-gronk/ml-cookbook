## 1. 自集成

- 自集成是一种集成学习方法，但与传统集成方法不同，它不需要训练多个独立模型
- 核心思想：模型在不同训练阶段具有互补的预测特性
- 定义
  - 在单个模型训练过程中，通过保存不同训练阶段的模型状态来构建集成
  - 预测时综合这些不同状态的输出，获得更稳定和鲁棒的预测结果

## 2. 伪标签

- 伪标签的定义来自半监督学习，半监督学习的核心思想是借助无标签的数据来提升有监督过程中的模型性能

#### 2.1 基础介绍

- 定义
  - 使用已训练的模型对未标注数据进行预测，将高置信度的预测结果作为 "伪标签"
  - 因为是无标注数据通过模型预测得到的标签，并非一定准确，因此称为 “伪标签”
  - 例如 训练集中有大量数据缺失标签，无法直接用于训练，可以生成伪标签丰富训练数据
- 使用步骤
  - 使用标记数据训练有监督模型 M
  - 使用有监督模型 M 对无标签数据进行预测，得出预测概率 P（ 需确保伪标签数据与原始数据分布相似 ）
  - 通过预测概率 P 筛选高置信度样本
  - 使用 有标记数据 以及 伪标签数据 训练新模型 M'
  - 将 M 替换成 M'，重复以上步骤直至模型效果 在验证集不出现提升 或 达到最大迭代次数
- 尝试变体
  - 协同训练：多个模型互相为对方生成伪标签
  - 自集成：多次添加伪标签得到的多个模型进行集成

#### 2.2 常用工具

- `sklearn.semi_supervised.SelfTrainingClassifier` 专门用于实现伪标签策略
  - 可以将任何标准的监督分类器转换为半监督分类器
  - 迭代地预测未标注数据的伪标签，并将高置信度的预测添加到训练集中
  - 核心参数
    - estimator：基础分类器实例
      - 必须实现 fit 和 predict_proba 方法
      - 例如：LogisticRegression(), RandomForestClassifier() 等
    - criterion：选择准则，默认为 'threshold'
      - 'threshold'：选择预测概率高于阈值的样本
      - 'k_best'：选择预测概率最高的 k_best 个样本
    - threshold：决策阈值，默认为 0.75
      - 当使用 criterion='threshold' 时，只有预测概率高于此值的样本会被添加为伪标签
      - 取值范围：[0, 1)
      - 重要：使用阈值准则时，基础分类器应该是经过良好校准的
    - k_best：每次迭代添加的样本数量，默认为 10
      - 仅当 criterion='k_best' 时使用
    - max_iter：最大迭代次数，默认为 10
      - 如果为 None，则持续迭代直到没有新伪标签或所有未标注样本都被标记

## 3. 对抗验证

- 实际应用中，训练集和测试集可能存在分布漂移，而 对抗验证 是一种检测数据集分布差异的技术
- 核心原理
  - 将训练集标记为类别 0，测试集标记为类别 1
  - 训练一个二分类模型来区分这两个 "类别"（ RandomForestClassifier 等 ）
  - 通过模型来评估两个数据集的分布相似度
    - 如果模型无法有效区分训练集和测试集，说明分布相似
    - 如果模型能够轻松区分，说明存在分布漂移，需要采取应对措施
- 通常选择 AUC 作为对抗验证的核心指标
  - 全面性：综合所有可能的分类阈值，提供整体评估
  - 鲁棒性：对类别不平衡不敏感，适应不同数据集大小
  - 可解释性：直接反映两个数据集的分离程度
  - 连续性：提供渐进式的风险评估，支持分层决策
  - 可比性：便于比较不同特征集或处理方法的效果
- 应对策略
  - 特征工程：移除导致分布差异的特征
  - 样本重加权：为与测试集分布相似的训练样本赋予更高权重
  - 预测调整：使用对抗权重调整最终预测结果
