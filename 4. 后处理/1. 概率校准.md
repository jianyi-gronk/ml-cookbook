## 1. 概率校准

#### 1.1 基础介绍

- 背景
  - 许多机器学习分类模型（ 如 支持向量机、决策树 等 ）输出的 “概率” 并不代表真实的概率
  - 它们通常是模型为了优化决策边界而生成的置信度分数，可能与样本属于某个类别的真实可能性存在偏差
  - 比如模型输出 0.8，理想情况下应该说明这个事情发生的概率为 80%。但在分类模型中，有可能输出 0.8 并不表示发生的概率为 80%
- 定义
  - 旨在将 分类模型 的 原始输出 映射到 真实的概率尺度 上
  - 其目标是，当模型预测一个事件的概率为 p 时，该事件发生的实际频率也应该是 p
- 导致概率不准的两个主要原因：**数据不平衡** 和 **模型选择**

#### 1.2 数据不平衡

- 训练数据严重不平衡的场景容易碰到模型输出的概率不准确，例如在风控、医疗诊断、网络安全等领域
- 模型偏差
  - 模型会倾向于预测多数类，导致对少数类的概率估计被系统性压低。即使模型能够正确区分，其输出的概率值也可能过于保守
  - 例如，一个确定性很高的正样本，模型只输出 0.6 的概率
- 评估失真
  - 在不平衡数据集上，准确率等指标会失效，而 AUC 虽然稳定，但无法反映概率的准确性
  - 因此，校准对于依赖概率进行决策（ 如风险定价 ）的场景至关重要

#### 1.3 模型选择

- **也可以理解是这些模型对应的 结构特性 和 损失函数 导致了 模型输出概率 和 真实概率 存在差别**
- 使用 模型校准曲线 `sklearn.calibration.calibration_curve` 评估不同分类模型的概率预测的校准效果，x 轴表示每个 bin（ 概率区间，把预测概率从 0 到 1 这一整条数轴等分成很多小区间 ）中的平均预测概率，y 轴是正数的分数，类别为正类别（ 在每个 bin 中 ）的样本比例
  ![image](https://scikit-learn.org.cn/upload/f4b22084adaac104b0606b8ed2a9dccb.png)
  - 标准算法曲线比较像对角线，比如 LogisticRegression
  - 缺乏自信的曲线是 sigmoid 形的，比如 RandomForestClassifier，SVC，输出概率总在 0.5 附近
  - 过于自信的曲线是反 sigmoid 形的，比如 naive bayes，输出概率不是 0 就是 1
- LogisticRegression
  - 在默认情况下返回经过良好校准的预测，因为它直接优化 log-loss（ 对数损失，专门用来衡量 “概率预测到底有多准” 的损失函数 ）
- GaussianNB
  - 倾向于将概率推到 0 或 1
  - 这主要是因为它假设在给定类的情况下，特征是条件独立的，这种情况下的数据集不会包含 2 个冗余特征的
- RandomForestClassifier
  - 直方图在大约 0.2 和 0.9 的概率下显示峰值，很难在 0 和 1 附近进行预测，因为基本模型中的方差会偏离应接近 0 或 1 这些值的预测，由于预测仅限于区间 \[0,1]，由方差引起的误差往往是在 0 和 1 附近的单边
  - 假设有 500 棵树在投票
    - 如果一个样本的真实概率应该是 0，那么要让随机森林输出 0.00，只有让 500 棵树必须全部投 0，这几乎不可能（ 对真实概率为 1 的样本也同理 ）
    - 在随机森林中观察到这种效应最为强烈，因为随机森林训练的基树由于特征子集而具有较高的方差
- LinearSVC
  - 比随机森林分类器更符合 sigmoid 形状的曲线，这是典型的最大边距方法，重点关注的是接近决策边界的硬样本（ 支持向量 ）

## 2. 解决方法

- 概率校准 需要在 独立的验证集（ 而非训练集 ）上进行，以防止过拟合
- 碰到多分类问题时，通常会将多分类问题分解为多个二分类问题

#### 2.1 Platt Scaling

- 原理
  - 这是一个参数化方法，会假设校准曲线符合逻辑斯谛分布
  - 将模型的原始输出分数（ 如 SVM 的决策函数值 ）通过一个逻辑回归函数进行拟合
- 公式
  $$P(y=1 | f(x)) = 1 / (1 + exp(A * f(x) + B))$$
  - 其中 f(x) 是模型的原始输出分数，A 和 B 是通过在验证集上最小化对数损失学习到的标量参数
- 适用场景
  - 适用于校准曲线呈 Sigmoid 形的模型，如 SVM、随机森林

#### 2.2 保序回归

- 原理
  - 一种非参数化方法，它不假设校准曲线的具体形状，只要求校准函数是单调递增的
  - 它通过将预测概率分箱，并调整每个箱内的概率值，使得调整后的曲线尽可能接近单调增的对角线
- 过程
  - 将验证集样本按模型原始预测概率排序
  - 划分成多个等宽或等深的箱（ Bins ）
  - 对每个箱，计算其内部样本的平均预测概率和平均真实标签（ 正例频率 ）
  - 通过保序回归算法，拟合一条非递减的阶梯函数，使得拟合值与真实频率尽可能接近
- 适用场景
  - 适用于任何形状的校准曲线，尤其当曲线不是简单的 Sigmoid 形时，它比 Platt Scaling 更灵活
  - 但它需要足够的数据来可靠地估计每个箱内的概率

#### 2.3 常用工具

- `sklearn.calibration.CalibratedClassifierCV` 是实现概率校准的主要工具
  - 它可以包装任何具有 predict_proba 方法或 decision_function 方法的分类器
  - 支持交叉验证方式校准，确保校准过程的可靠性
  - 核心参数
    - estimator：需要进行校准的基础分类器实例，默认为 LinearSVC
    - method：校准方法，可选 'sigmoid'（ Platt Scaling ）或 'isotonic'（ 保序回归 ）
    - cv：交叉验证策略
      - 整数：指定折数
      - 'prefit'：表示基础分类器已经预训练，直接使用提供的验证集进行校准
      - 交叉验证迭代器
    - n_jobs：并行运行的作业数
    - ensemble: 布尔值 或 "auto"，默认为 "auto"
      - "auto"
        - 如果基础估计器是 FrozenEstimator，则使用 False，否则使用 True
      - True
        - 对每个交叉验证折，使用训练数据拟合基础估计器，并使用测试数据进行校准
        - 最终估计器是 n_cv 个（ 分类器+校准器 ）对的集成，预测时输出所有对预测概率的平均值
      - False
        - 使用 cross_val_predict 计算无偏预测，然后用于校准
        - 在预测时，使用的分类器是在所有数据上训练的

## 3. 评估

- 评估概率校准效果，需要使用与模型训练时不同的指标

#### 3.1 对数损失

- 公式
  $$
  Log\_Loss = - (1/N) * ∑ [y_i * log(p_i) + (1 - y_i) * log(1 - p_i)]
  $$
  - 衡量了预测概率与真实标签之间的交叉熵，值越小越好，0 表示完美预测
  - 它对预测错误的置信度 惩罚极大（ 例如，真实为 1 的样本被预测为 0.01 的概率，会产生很大的损失 ）
  - 一个经过良好校准的模型通常具有较低的对数损失

#### 3.2 Brier 分数

- 公式
  $$
  Brier\_Score = \frac{1}{N} \sum_{i=1}^{N} (y_i - p_i)^2
  $$
  - 衡量了预测概率与真实标签之间的均方误差，值越小越好，0 表示完美预测
  - Brier 分数可以分解为校准损失、refinement 损失 和 不确定性，因此，它直接反映了概率校准的好坏
