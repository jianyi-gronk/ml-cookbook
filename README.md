- 主要是用来介绍人工智能的核心步骤，是以 kaggle 实践为例，整个学习笔记也是围绕着这个展开

## 1. 数据预处理

#### 1.1 数据的重要性

- **数据质量决定模型上限**，噪音，缺失值，格式混乱（ 多时区时间戳 ）等问题都会导致模型偏差
- **原始数据可能不符合模型的输入要求**，比如 部分决策树模型要求分类编码，神经网络要求数值型 等
- **不规整的数据会导致梯度下降收敛速度降低**，影响训练速度，当特征尺度差异较大时（ 如特征 A 取值 0-1，特征 B 取值 1000-10000 ），损失函数等高线会呈现狭长椭圆形，这种导致：
  - 梯度方向偏移：实际最优方向与梯度方向形成夹角
  - 震荡路径：梯度下降在陡峭维度频繁震荡
  - 迭代次数倍增：需要更多 "之" 字形路径才能到达最低点

#### 1.2 主要步骤

- **数据加载**
  - 核心是将原始数据从存储源导入计算环境，并初步解析为可操作的结构
- **数据清洗**
  - 核心是将不符合预期的数据进行处理
- **数据扩充**
  - 通过原始数据集，生成新的数据集
- **数据转换**
  - 核心是将数据转换成更适合模型输入的类型
- **特征工程**
  - 核心是在特征数量少，或者特征信息量不足的情况，进行特征构造；在冗余特征多的情况，进行特征选择
- **数据分割**
  - 核心是将原始数据划分为独立的 训练集，验证集 和 测试集

## 2.  模型训练

- 通常核心目标为 **学习一个函数，使其在未知数据上预测的误差最小化**
- 这需要两步实现
  - **优化**：在训练集上最小化代价函数（ 也叫损失函数 ）
  - **泛化**：通过 正则化，早停机制，模型简化 等确保学到的规律可泛化到新数据

## 3. 模型调优

- **模型评估**
  - 评估方法：交叉验证
  - 评估指标
    - 分类：准确率、F1-score、AUC-ROC 等
    - 回归：R²、MAE、RMSE 等
  - 和代价函数非常相似，但是还是存在差异
    - 代价函数用于训练阶段的反向传播，而模型评估用于训练后的验证/测试阶段
    - 代价函数用于指导参数优化，而模型评估用于量化模型在任务上的表现
    - 代价函数有更多的数学特性要求，比如梯度下降中要求可导，而模型评估通常没有要求
- **超参数优化**
  - 网格搜索，随机搜索，贝叶斯优化，TPE 等
  - 目前 Optuna 自动化调参工具在 kaggle 中广泛应用
- **模型集成**
  - 当单个模型 CV 分数达到排行榜 80%-90% 分位时，再继续优化单模型的边际收益会显著下降，可以开始构建集成
  - 集成的模型最好得分不要太低，且之间关联性最好较弱
  - 常见方法：Voting/Averaging，Bagging，Boosting，Stacking 和 Blending
