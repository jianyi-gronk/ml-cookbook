- 主要是介绍人工智能的核心步骤，是以 kaggle 实践为例，整个学习笔记也是围绕着这个展开

## 1. 数据预处理

#### 1.1 数据的重要性

- **数据质量决定模型上限**，噪音，缺失值，格式混乱（ 多时区时间戳 ）等问题都会导致模型偏差
- **原始数据可能不符合模型的输入要求**，比如 部分决策树模型要求分类编码，神经网络要求数值型 等
- **不规整的数据会导致梯度下降收敛速度降低**，影响训练速度，当特征尺度差异较大时（ 如特征 A 取值 0-1，特征 B 取值 1000-10000 ），损失函数等高线会呈现狭长椭圆形，这种导致：
  - 梯度方向偏移：实际最优方向与梯度方向形成夹角
  - 震荡路径：梯度下降在陡峭维度频繁震荡
  - 迭代次数倍增：需要更多 "之" 字形路径才能到达最低点

#### 1.2 主要步骤

- **数据加载**
  - 核心是将原始数据从存储源导入计算环境，并初步解析为可操作的结构
- **数据清洗**
  - 核心是将不符合预期的数据进行处理
- **数据扩充**
  - 通过原始数据集，生成新的数据集
- **数据转换**
  - 核心是将数据转换成更适合模型输入的类型
- **特征工程**
  - 核心是在特征数量少，或者特征信息量不足的情况，进行特征构造；在冗余特征多的情况，进行特征选择
- **数据分割**
  - 核心是将原始数据划分为独立的 训练集，验证集 和 测试集

## 2. 模型训练

#### 2.1 核心

- 通常核心目标为 **学习一个函数，使其在未知数据上预测的误差最小化**
- 这需要两步实现
  - **优化**：在训练集上最小化代价函数（ 也叫损失函数 ）
  - **泛化**：通过 正则化，早停机制，模型简化 等确保学到的规律可泛化到新数据

#### 2.2 主要步骤

- **模型评估**
  - 评估方法：交叉验证
  - 评估指标
    - 分类：准确率、F1-score、AUC-ROC 等
    - 回归：R²、MAE、RMSE 等
  - 和代价函数非常相似，但是还是存在差异
    - 代价函数用于训练阶段的反向传播，而模型评估用于训练后的验证/测试阶段
    - 代价函数用于指导参数优化，而模型评估用于量化模型在任务上的表现
    - 代价函数有更多的数学特性要求，比如梯度下降中要求可导，而模型评估通常没有要求
- **超参数优化**
  - 网格搜索，随机搜索，贝叶斯优化，TPE 等
  - 目前 Optuna 自动化调参工具在 kaggle 中广泛应用

## 3. 后处理

- **概率校准**
  - 树模型尤其是 LightGBM 默认概率严重失真
  - 常用校准方法
    - Platt Scaling：logistic 回归，适合大数据量
    - Isotonic Regression：非参数，样本少时更稳
- **阈值优化**（ 分类任务 ）
  - 比赛指标是 F1、F2、Recall@k、Precision@k 时，最优阈值几乎从来不是 0.5
  - 具体使用：在本地 OOF 预测结果上用 precision_recall_curve 或直接搜最优阈值
- **模型集成**
  - 当单个模型 CV 分数达到排行榜 80%-90% 分位时，再继续优化单模型的边际收益会显著下降，可以开始构建集成
  - 集成的模型最好得分不要太低，且之间关联性最好较弱
  - 常见方法
    - Voting/Averaging
    - Bagging
    - Boosting
    - Stacking
    - Blending
    - Hill Climbing：贪心法，一个一个加集成模型，只保留能提升的
- **伪标签与自集成**
  - 用当前最强 ensemble 预测 test，取置信度 >0.95（ 或 0.99 ）的样本加入训练集继续训练
  - 具体使用：迭代 2~3 轮 + 逐步降低阈值
- **Snap 化处理（ 回归到最近有效值 ）**
  - 比赛标签是整数或特定离散值（如评分 1~5）时，把预测值四舍五入到最近的有效值
  - 常见于房价、评分、计数类回归赛
- **对抗验证（Adversarial Validation）后处理**
  - 用对抗验证算出 train 和 test 每行的分布差异概率
  - 最终预测 = 原始预测 × (1 − adv_weight) + 全局均值 × adv_weight
  - 能显著降低因分布漂移导致的 Private LB 下降过大
