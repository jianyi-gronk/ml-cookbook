## 1. EfficientNet

- [参考资料](https://www.cnblogs.com/yirui/p/16320175.html)，[参考资料](https://cloud.tencent.com/developer/article/1580853)
- EfficientNet 是一种高效的卷积神经网络架构，由谷歌研究团队在 2019 年提出。它的设计理念是通过改进网络结构、扩展网络深度和宽度以及使用复合缩放方法来提高模型的效率和准确性。相比于传统的卷积神经网络，EfficientNet 在保持相对较小的模型参数数量的情况下，能够提供更好的性能表现，特别是在计算资源有限的情况下，如移动设备或边缘设备上的应用
- EfficientNet 是一种高效，可扩展的卷积神经网络结构，它是通过自动模型缩放方法得到的。

## 2. 复合缩放系数

#### 2.1 以前痛点

- 在之前的一些手工设计网络，对于深度，宽度 和 分辨率的控制都是按照工程经验去设置，没有一个设计准则和有效的优化方案，根据过往经验
  - 深度（ depth ）：
    - 网络中的层数
    - 增加网络的深度能够得到更加丰富、复杂的特征并且能够很好的应用到其它任务中，但网络的深度过深会面临梯度消失，训练困难的问题
  - 宽度（ width ）：
    - 每层网络的输入输出通道数
    - 增加网络的宽度能够获得更高细粒度的特征并且也更容易训练，但对于宽度很大而深度较浅的网络往往很难学习到更深层次的特征
  - 分辨率（ resolution ）：
    - 输入图像的尺寸
    - 增加输入网络的图像分辨率能够潜在得获得更高细粒度的特征模板，但对于非常高的输入分辨率，准确率的增益也会减小。并且大分辨率图像会增加计算量

#### 2.2 算法思想

- 论文提出用神经网络搜索算法（ Neural Architecture Search，NAS ）技术来搜索网络的 分辨率，深度 和 宽度 三个参数的合理化配置，得到新的基准网络，然后对其进行模型缩放，得到一系列网络 EfficientNets
- 论文提出只需要常数比率，就可以维持三个维度的平衡，进而进行有效的网络扩展，因此提出一个简单而且有效的复合扩展方法，与之前任意扩展网络的操作不同，我们使用一组固定的缩放系数对三个维度进行扩展，比如，如果需要使用 $2^N$ 的计算资源，我们可以简单的提高深度 $α^N$，宽度 $β^N$ 和图像大小 $γ^N$，这里 α，β，γ 是在最小的模型上搜索得到
- EfficientNet 的模型结构可以表示为 EfficientNet B{N}，也称之模型族 EfficientNets，其中 N 是一个整数，表示模型的大小，目前，EfficientNet 提供了 B0 到 B7 七个不同大小的模型，可以根据具体任务的需求选择合适的模型，模型大小越大，性能越好，但计算和存储成本也越高
- 复合缩放系数包括一个深度缩放系数、一个宽度缩放系数和一个分辨率缩放系数，这些缩放系数通过一个复合函数进行组合，得到最终的缩放系数，用于调整模型结构。可以避免手动调整网络结构的繁琐过程，同时提高了模型的效率和准确性
  ![image](https://github.com/user-attachments/assets/99bba53d-8487-4118-9e07-3fc993523c65)

## 3. 网络结构

#### 3.1 effcientNet-B0

- EfficientNet-B0 的网络框架（ B1-B7 就是在 B0 的基础上修改 分辨率，深度 和 宽度 三个参数 ），可以看出网络总共分成了 9 个 Stage
- 第一个 Stage 就是一个卷积核大小为 3 x 3 步距为 2 的普通卷积层（ 包含 BN 和激活函数 Swish ），Stage2 ～ Stage8 都是在重复堆叠 MBConv 结构（ 最后一列的 Layers 表示该 Stage 重复 MBConv 结构的次数），而 Stage9 由一个普通的 1 x 1 的卷积层（ 包含 BN 和激活函数 Swish ）一个平均池化层和一个全连接层组成
- 每个 MBConv 后会跟一个数字 1 或 6，这里的 1 或 6 就是倍率因子 n 即 MBConv 中第一个 1x1 的卷积层会将输入特征矩阵的 channels 扩充为 n 倍，其中 k3x3 或 k5x5 表示 MBConv 中 Depthwise Conv 所采用的卷积核大小。Channels 表示通过该 Stage 后输出特征矩阵的 Channels

#### 3.2 EfficientNet（ B0-B7 ）参数

- 参数如下
  ![image](https://github.com/user-attachments/assets/d7eb4ed2-20bc-46ba-981c-f3b713c33ee5)
  - input_size：输入图像大小
  - width_coefficient：channel 维度的倍率因子（ 取整到最近的 8 的倍数：32 \* 1.2 = 38.4，取 40 ）
  - depth_coefficient：depth 维度的倍率因子（ 针对 stage2 ～ stage8，向上取整，比如在 EfficientNetB0 中 Stage7 的 $L_i$ = 4，那么在 B6 中就是 4 \* 2.6 = 10.4 接着向上取整即 11 ）
  - drop_connect_rate：MBconv 结构中的 dropout 层的比例
  - drop_rate：最后一个全连接层的 dropout 层的比例

#### 4 MBConv

- MBConv 结构主要由一个 1x1 的普通卷积（ 升维作用，包含 BN 和 Swish ），一个 k x k 的 Depthwise Conv 卷积（ 包含 BN 和 Swish ）k 的具体值可看 EfficientNet-B0 的网络框架主要有 3 x 3 和 5 x 5 两种情况，一个 SE 模块，一个 1x1 的普通卷积（ 降维作用，包含 BN ），一个 DropConnect 层构成
  ![image](https://github.com/user-attachments/assets/4de4094e-a9bf-494e-b901-c2da7fe970ed)
- 结构简化来看
  ![image](https://github.com/user-attachments/assets/000082f8-93d2-49c1-b747-f1e8c5e37a13)
- 第一个升维的 1 x 1 卷积层，它的卷积核个数是输入特征矩阵 channel 的 n 倍，n ∈ {1, 6}
- 当 n = 1 时，不要第一个升维的 1 x 1 卷积层，即 Stage2 中的 MBConv 结构都没有第一个升维的 1x1 卷积层（ 这和 MobileNetV3 网络类似 ）
- 关于 shortcut 连接，仅当输入 MBConv 结构的特征矩阵与输出的特征矩阵 shape 相同时才存在（ 代码中可通过 stride == 1 and inputc_channels == output_channels 条件来判断 ）
- SE 模块由一个全局平均池化，两个全连接层组成。第一个全连接层的节点个数是输入该 MBConv 特征矩阵 channels 的 1 / 4，且使用 Swish 激活函数。第二个全连接层的节点个数等于 Depthwise Conv 层输出的特征矩阵 channels，且使用 Sigmoid 激活函数
- Dropout 层的 dropout_rate 在 tensorflow 的 keras 源码中对应的是 drop_connect_rate 后面会细讲（ 注意，在源码实现中只有使用 shortcut 的时候才有 Dropout 层 ）
- 还使用了一些其他的技术来提高模型的性能，其中最重要的是 Swish 激活函数，它比常用的 ReLU 激活函数具有更好的性能。此外，EfficientNet 还使用了 DropConnect 技术来防止过拟合，并使用了标准化技术来提高模型的稳定性

#### 4.1 Swish 激活函数

- 公式为
  ![image](https://github.com/user-attachments/assets/ec5bf849-206d-4c83-a005-6cee58fc2b01)
- 图像为
  ![image](https://github.com/user-attachments/assets/42c34b8e-07e1-4ddc-b77b-b4209e340927)
- 特点
  - 和 ReLU 一样，没有上边界，因此不会出现梯度饱和现象
  - 有下边界，可以产生更强的正则化效果（ x 左半轴慢慢趋于 0 ）
  - 非单调
  - 处处连续可导，更容易训练

#### 4.2 DropConnect

- DropConnect 与 Dropout 不同的地方是在训练神经网络模型过程中，它不是对隐层节点的输出进行随机的丢弃，而是对隐层节点的输入进行随机的丢弃
  ![image](https://github.com/user-attachments/assets/0bc4d335-23a6-443d-82da-4a9b7b49ff64)
- 在深度神经网络中 DropConnect 与 Dropout 的作用都是防止模型产生过拟合的情况。相比之下 DropConnect 的效果会更好一些

## 4. ImageNet 上的性能结果

![image](https://github.com/user-attachments/assets/fb2a22c4-66fd-41d3-b99c-2d359f1c23bd)
