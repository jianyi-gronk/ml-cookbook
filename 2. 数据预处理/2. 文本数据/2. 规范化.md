## 1. 规范化

- 规范化通过将不同形式的词或表达归一化为统一格式，减少词汇的多样性，降低噪声，便于后续分析或建模
- 常用方法
  - 去除停用词（ Stop Words Removal ）
  - 词干提取（ Stemming ）
  - 词形还原（ Lemmatization ）
  - 转换为小写（ Lowercasing ）
  - 拼写校正（ Spell Correction ）
  - 去除标点或特殊字符

## 2. 去除停用词

- **从文本数据中移除那些对分析或建模贡献较小的常见词汇，以减少噪声、降低计算复杂度和提高模型性能**

#### 2.1 停用词

- 停用词是指在语言中频繁出现但通常不携带重要语义信息的词，例如
  - 英文中的停用词：如 “the”，“is”，“and”，“in”，“to“ 等
  - 中文中的停用词：如 “的”，“了”，“是”，“在”，“和” 等

#### 2.2 操作步骤

- 在去除停用词之前，通常需要对文本进行分词，将句子拆分为单个词或标记（ tokens ）
- 准备停用词列表
  - 使用预定义的停用词列表，如 NLTK、spaCy 等库提供的英文停用词表，或 中文的哈工大停用词表、百度停用词表 等
  - 根据具体任务自定义停用词列表，添加或移除某些词
- 过滤停用词
  - 遍历分词后的词列表，检查每个词是否在停用词列表中
  - 如果是停用词，则将其从文本中移除，否则保留

#### 2.3 示例

- 输入文本
  - “我在学校学习自然语言处理”
- 分词后
  - [我，在，学校，学习，自然，语言，处理]
- 停用词列表（ 假设 ）
  - [在，的，是，了]
- 去除停用词后
  - [我，学校，学习，自然，语言，处理]

#### 2.4 适用场景

- 适用于那些需要聚焦于文本核心语义、减少噪声或降低计算复杂度的任务
- 适用场景
  - 文本分类（ 如情感分析、垃圾邮件检测 ）
    - 停用词（如 “的”，“是”，“and”，“the”）通常对分类任务的语义贡献较小，去除它们可以让模型更关注关键词（如“高兴”“垃圾邮件”），提高分类准确性
  - 信息检索与搜索引擎
    - 搜索查询中，停用词（ 如 “in”，“to” ）通常不影响检索结果的主题相关性，去除停用词可以减少索引大小，提高检索效率
  - 主题建模（ 如 LDA、TF-IDF ）
    - 原因：主题建模关注文本中的主题词，停用词是高频词但与主题无关，去除它们可以提升主题的清晰度
  - 关键词提取
    - 停用词不具备代表性，去除它们可以突出更有意义的关键词
  - 降低计算复杂度
    - 在处理大规模文本数据时，去除高频停用词可以减少词汇表大小，降低内存和计算成本
  - 特定语言环境
    - 在英文中，停用词（ 如 “the”，“is”）通常语法功能强，语义贡献弱，适合移除
    - 在中文中，某些高频虚词（ 如 “的”，“了” ）在特定任务中也可以移除以减少噪声

#### 2.5 不适用场景

- 不适用于需要保留文本完整语义、语法结构或上下文的任务
- 不适用场景
  - 机器翻译
    - 停用词在翻译中对语法结构和句子流畅性至关重要，去除它们可能导致翻译结果不自然或语法错误
  - 文本生成（ 如对话系统、文章生成 ）
    - 生成任务需要完整的句子结构，停用词对生成自然、连贯的文本至关重要
  - 序列模型任务（ 如 NER、POS 标注 ）
    - 命名实体识别（ NER ）或词性标注（ POS tagging ）依赖于完整的句子上下文，停用词可能提供重要的语法线索
  - 上下文敏感的模型（ 如 BERT、Transformer ）
    - 现代预训练模型（ 如 BERT ）通过上下文学习词的语义，停用词在这些模型中可能提供重要的上下文信息，去除它们可能降低模型性能
  - 短文本分析
    - 在短文本（ 如 短信 ）中，停用词可能占据较大比例，去除它们可能导致信息丢失，影响语义分析

## 3. 词干提取

#### 3.1 基础介绍

- 原理
  - **通过规则或启发式算法，将单词的不同形态（ 如时态、复数、比较级 ）简化为共同的词干形式，去除词缀（ 如 “-ing”，“-ed”，“-s” ）**
  - 输出不一定是合法单词
- 目的
  - 减少词汇变体，降低词汇表大小，提高计算效率
- 适用场景
  - 信息检索，如搜索引擎匹配 “run” 相关词
  - 文本分类，减少特征维度
  - 关键词提取，突出核心词
- 局限性
  - 输出可能是非合法单词，如 “studies” → “studi”
  - 不考虑语义，可能导致歧义
  - 中文较少使用，因缺乏复杂词形变化

#### 3.2 示例

- 输入：“running, runner, runs”
- 输出：“run”
- 输入：“studies, studying, studied”
- 输出：“studi”
- 输入：“better, best”
- 输出：“good”

#### 3.3 常用算法

- 常用工具：NLTK、spaCy
- Porter Stemmer：基于多步规则移除后缀，广泛应用于英文
- Snowball Stemmer：Porter 的改进版，支持多语言
- Lancaster Stemmer：更激进，可能移除更多字符

## 4. 词形还原

- 原理
  - **词形还原是将单词的不同形态还原为标准字典形式（ 即词元，lemma ），基于词典和语义分析**
  - 输出是合法单词
- 目的
  - 在保留语义的基础上规范化词汇，适用于需要精确语义的任务
- 适用场景
  - 机器翻译，需要合法单词
  - 文本生成，生成自然句子
  - 命名实体识别，NER，需完整语义
- 局限性
  - 计算成本较高，需词典支持
  - 对不在词典中的词，处理效果较差
  - 中文使用较少，因词形变化不明显
- 与词干提取的区别
  - 词干提取：规则驱动，输出可能非单词，速度快
  - 词形还原：语义驱动，输出合法单词，精度高

#### 4.2 示例

- 输入：“running, runner, runs”
- 输出：“run”
- 输入：“studies, studying, studied”
- 输出：“study”
- 输入：“better, best”
- 输出：“good”

## 5. 其他规范化方法

#### 5.1 转换为小写

- 定义：将文本中的所有字符转换为小写，以统一大小写形式，减少因大小写不同导致的词汇变体
- 目的：确保相同含义的词（ 如 “Apple” 和 “apple” ）被视为同一个词，降低词汇表大小
- 适用场景
  - 文本分类，忽略大小写差异
  - 信息检索，统一查询和文档中的词
  - 关键词提取，避免重复关键词

#### 5.2 拼写校正

- 定义：纠正文本中的拼写错误，如 “recieve” → “receive”
- 目的：提高数据质量，统一拼写形式
- 工具：TextBlob、pyspellchecker

#### 5.3 去除标点和特殊字符

- 定义：移除标点符号（ 如“,”，“!” ）或特殊字符（ 如 “@”，“#” ）
- 目的：简化文本，减少无关特征
- 示例：输入 “Hello, world!” → 输出 “Hello world”
- 适用场景：关键词提取、词袋模型
