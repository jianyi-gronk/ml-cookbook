- **核心是将原始数据从存储源导入计算环境，并初步解析为可操作的结构**

## 1. 声明数据类型

- 读取的数据时，可以明确指定 dtype（ 数据类型 ），可以有效 **优化加载速度** 和 **减少内存占用**

#### 1.1 问题背景

- 因为 Pandas 等库在读取数据（ 尤其是 CSV ）时，会尝试自动推断每一列的数据类型。为了安全起见，它通常会选择比实际需要更宽泛、占用更多内存的类型。例如：
  - 一个只包含 0 和 1 的列，可能被推断为 int64，而它只需要 int8 或 bool
  - 一个只包含 1.0, 2.0, 3.0 的列，可能被推断为 float64，而它只需要 float32 甚至 int8
  - 一个取值范围有限的字符串列（ 如国家名、产品类别 ），默认是 object（ 存储指针，开销大 ），可以转换为 category 类型（ 使用整数编码，存储开销显著降低 ）

#### 1.2 如何声明类型

- 自动推断
  - df.convert_dtypes() 是一个 Pandas 函数，用于尝试将 DataFrame 的每个列转换为最紧凑的类型，但手动指定通常更优且可控
- 手动设置

  ```python
  import pandas as pd
  import numpy as np

  # 示例：指定特定列的类型
  dtypes = {
      'user_id': np.int32,        # 32 位整数代替默认的 64 位
      'age': np.uint8,            # 无符号 8 位整数 ( 0-255 )
      'price': np.float32,         # 32 位浮点数代替默认的 64 位
      'is_active': bool,           # 布尔值
      'country': 'category',       # 分类类型，极大节省内存用于重复值多的字符串
  }

  df = pd.read_csv('large_data.csv', dtype=dtypes)
  ```

## 2. 只加载需要的列

- 只加载需要的列，避免加载不必要的数据，从而减少内存占用
  ```python
  import pandas as pd
  # 只加载需要的列
  columns_to_load = ['user_id', 'age', 'price', 'is_active', 'country']
  df = pd.read_csv('large_data.csv', usecols=columns_to_load)
  ```

## 3. Polars 替换 Pandas

#### 3.1 两者差异

- 两者对比
  - 和 Pandas 相比，Polars 的速度更快，执行常见运算的速度是 Pandas 的 5 到 10 倍。
  - 另外 Polars 运算的内存需求也明显小于 Pandas，Pandas 需要数据集大小的 5 到 10 倍左右的 RAM 来执行运算，而 Polars 需要 2 到 4 倍
  - 但是 Pandas 更成熟，社区支持更好，与其他库的集成也更好
- Polars 更优异的原因：
  - 以 Rust 编写从 0 编写
    - 没有扩展依赖，低级语言速度快
    - 使用 Rust 的另一个优点是它允许安全并发，使并行性尽可能可预测。这意味着 Polars 可以安全使用所有机器核心执行涉及多个列的复杂查询
  - 基于 Apache Arrow 上构建数据库，一种独立于语言的内存格式
  - 查询优化
    - Polars 性能的另一个核心是评估代码的方式。Pandas 默认使用 Eager 执行，按照编写的顺序执行运算。相比之下，Polars 能够同时执行 Eager 和惰性执行，查询优化器将对所有必需运算求值并制定最有效的代码执行方式。这可能包括重写运算的执行顺序或删除冗余计算
  - 表达性 API
    - Polars 拥有一个极具表达性的 API，基本上想执行的任何运算都可以用 Polars 方法表达
    - 相比之下，pandas 中更复杂的运算通常需要作为 lambda 表达式传递给 apply 方法。apply 方法的问题是它循环遍历 DataFrame 的行，对每一行按顺序执行运算。内置方法能够在列级别上工作并利用另一种称为 SIMD 的并行形式

#### 3.2 运行时间对比

- 数据读取

  ```python
  # train.parquet: 2.35G

  # Pandas dataframe
  train_pd = pd.read_parquet('/Users/Downloads/archive/train.parquet')
  # Polars dataframe
  train_pl = pl.read_parquet('/Users/Downloads/archive/train.parquet')

  # CPU times: user 3.85 s, sys: 8.69 s, total: 12.5 s
  # Wall time: 10.4 s
  # CPU times: user 3.07 s, sys: 2.22 s, total: 5.29 s
  # Wall time: 3.39 s
  ```

- 聚合操作

  ```python
  # pandas query
  nums = ["num_7", "num_8", "num_9", "num_10", "num_11", "num_12", "num_13", "num_14", "num_15"]
  cats = ["cat_1", "cat_2", "cat_3", "cat_4", "cat_5", "cat_6"]
  train_pd[nums].agg(['min','max','mean','median','std'])
  # Polars query
  train_pl.with_columns([
    pl.col(nums).min().suffix('_min'),
    pl.col(nums).max().suffix('_max'),
    pl.col(nums).mean().suffix('_mean'),
    pl.col(nums).median().suffix('_median'),
    pl.col(nums).std().suffix('_std'),
  ])

  # CPU times: user 6.06 s, sys: 4.19 s, total: 10.3 s
  # Wall time: 15.8 s
  # CPU times: user 4.51 s, sys: 5.49 s, total: 10 s
  # Wall time: 8.09 s
  ```

- 查询后计算

  ```python
  # Pandas filter and select
  train_pd[train_pd['cat_1']==1][nums].mean()
  # Polars filter and select
  train_pl.filter(pl.col("cat_1") == 1).select(pl.col(nums).mean())

  # CPU times: user 730 ms, sys: 1.65 s, total: 2.38 s
  # Wall time: 4.24 s
  # CPU times: user 659 ms, sys: 3.22 s, total: 3.88 s
  # Wall time: 2.12 s
  ```

- 分类再聚合

  ```python
  Function_3 = train_pd.groupby(['user'])[nums].agg('mean')
  Function_3 = train_pl.groupby('user').agg(pl.col(nums).mean())

  # CPU times: user 2.4 s, sys: 938 ms, total: 3.33 s
  # Wall time: 3.46 s
  # CPU times: user 6.92 s, sys: 2.68 s, total: 9.6 s
  # Wall time: 1.78 s
  ```

- 排序

  ```python
  cols=['user','num_8'] # columns to be used for sorting

  # Sorting in Pandas
  a = train_pd.sort_values(by=cols,ascending=True)
  # Sorting in Polars
  b = train_pl.sort(cols,descending=False)

  # CPU times: user 31.9 s, sys: 7.28 s, total: 39.2 s
  # Wall time: 46.2 s
  # CPU times: user 32.2 s, sys: 7.04 s, total: 39.2 s
  # Wall time: 11.6 s
  ```

## 4. cuDF 替换 Pandas

- 如果想使用 GPU 加速，通常使用 cuDF，它是 NVIDIA 开发的基于 CUDA 的 GPU 加速 DataFrame 库，旨在通过 GPU 的并行计算能力大幅提升大规模数据处理效率

#### 4.1 核心介绍

- GPU 并行加速
  - 基于 Apache Arrow 列式内存格式构建，利用 CUDA 核心实现数据操作的并行化
  - 对比 Pandas，在十亿级行数据聚合操作中可提速 10-100 倍
- 类 Pandas API 设计
  - 提供 DataFrame、Series 等数据结构，支持 groupby、join、filter 等常见操作，代码迁移成本低
  - 示例代码
    ```python
    import cudf
    df = cudf.read_csv("large_data.csv")
    df["new_col"] = df["col1"] * df["col2"]
    result = df.groupby("category").mean()
    ```
- 高效内存管理
  - 数据存储于 GPU 显存，支持显存不足时通过 Dask-cuDF 分布式扩展（ 多 GPU/多节点 ）

#### 4.2 与 Pandas 的关键差异

| 特性           | cuDF                               | Pandas              |
| -------------- | ---------------------------------- | ------------------- |
| 缺失值表示     | `cudf.NA`（ 全数据类型可空 ）      | `NaN`（ 仅浮点型 ） |
| 索引排序       | Join/GroupBy 默认不排序            | 默认排序            |
| 列名           | 禁止重复列名                       | 允许重复列名        |
| 迭代操作       | 不支持（ GPU 并行优化限制 ）       | 支持                |
| 浮点运算确定性 | 非确定（ GPU 并行计算顺序不可控 ） | 确定                |
| 对象数据类型   | 不支持任意 Python 对象             | 支持                |

#### 4.3 适用场景

- 大规模数据处理
  - 单 GPU 场景：适合显存可容纳的数据集（ 如 1GB–100GB ）
  - 分布式场景：通过 Dask-cuDF 处理 TB 级数据（ 如 分布式聚合分析 ）
- 计算密集型任务加速
  - 特征工程：GPU 并行加速特征变换（ 如 亿级行数据标准化 ）
  - 聚合查询：GroupBy/Join 操作在 GPU 上并行执行，比 Pandas 快 50 倍以上
- 与 GPU 生态集成
  - 机器学习预处理：与 cuML（GPU 加速的 ML 库）无缝衔接，加速特征工程到模型训练流程
  - 可视化支持：快速输出预处理结果至 Plotly/Matplotlib（ 需转换为 Pandas ）

#### 4.4 生态扩展

- Dask-cuDF：分布式计算框架，支持多 GPU 并行处理超显存数据
- cuML：GPU 加速的机器学习库，与 cuDF 协同完成端到端加速
- cudf.pandas 兼容层：无代码修改加速现有 Pandas 脚本（ 自动回退 CPU 处理未实现操作 ）

  ```python
  # 启用 cudf.pandas 兼容层（ 必须在导入 pandas 前执行 ）
  import cudf.pandas
  cudf.pandas.install()

  # 现在导入的 pandas 实际是 GPU 加速版本
  import pandas as pd
  # 之后 pd 正常使用...
  ```

  - 原理是 cudf.pandas.install() 会用 cuDF API 覆盖 pandas 命名空间
    - 将 pd.DataFrame 替换为 cudf.DataFrame
    - 将 pd.Series 替换为 cudf.Series
    - 保留所有原生 Pandas 方法调用语法
