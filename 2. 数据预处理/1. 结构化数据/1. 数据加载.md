- **核心是将原始数据从存储源导入计算环境，并初步解析为可操作的结构**

## 1. 声明数据类型

- 读取的数据时，可以明确指定 dtype（ 数据类型 ），可以有效 **优化加载速度** 和 **减少内存占用**

#### 1.1 问题背景

- 因为 Pandas 等库在读取数据（ 尤其是 CSV ）时，会尝试自动推断每一列的数据类型。为了安全起见，它通常会选择比实际需要更宽泛、占用更多内存的类型。例如：
  - 一个只包含 0 和 1 的列，可能被推断为 int64，而它只需要 int8 或 bool
  - 一个只包含 1.0, 2.0, 3.0 的列，可能被推断为 float64，而它只需要 float32 甚至 int8
  - 一个取值范围有限的字符串列（ 如国家名、产品类别 ），默认是 object（ 存储指针，开销大 ），可以转换为 category 类型（ 使用整数编码，存储开销显著降低 ）

#### 1.2 如何声明类型

- 自动推断
  - df.convert_dtypes() 是一个 Pandas 函数，用于尝试将 DataFrame 的每个列转换为最紧凑的类型，但手动指定通常更优且可控
- 手动设置

  ```python
  import pandas as pd
  import numpy as np

  # 示例：指定特定列的类型
  dtypes = {
      'user_id': np.int32,        # 32 位整数代替默认的 64 位
      'age': np.uint8,            # 无符号 8 位整数 ( 0-255 )
      'price': np.float32,         # 32 位浮点数代替默认的 64 位
      'is_active': bool,           # 布尔值
      'country': 'category',       # 分类类型，极大节省内存用于重复值多的字符串
  }

  df = pd.read_csv('large_data.csv', dtype=dtypes)
  ```

## 2. 只加载需要的列

- 只加载需要的列，避免加载不必要的数据，从而减少内存占用
  ```python
  import pandas as pd
  # 只加载需要的列
  columns_to_load = ['user_id', 'age', 'price', 'is_active', 'country']
  df = pd.read_csv('large_data.csv', usecols=columns_to_load)
  ```
