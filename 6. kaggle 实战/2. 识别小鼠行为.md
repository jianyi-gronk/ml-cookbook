## 1. 题目介绍

- 题目：[根据小鼠的运动来识别其行为](https://www.kaggle.com/competitions/MABe-mouse-behavior-detection)
- 数据集：由约 1000+ 个视频组成，每个视频包含关键点追踪数据（ Parquet 格式 ），总帧数约 4000 万，包含
  - train.csv / test.csv：视频元信息，如 lab_id、video_id、fps、behaviors_labeled JSON 字符串、pix_per_cm_approx
  - train_tracking/\*.parquet：每帧每鼠每个小鼠身体部分 body_part 的 (x, y) 坐标，身体部分可能包括 nose、ear_left、tail_base 等 5~18 个关键点
  - train_annotation/\*.parquet：训练集行为标注，仅 train
- 特征
  - 视频元信息
    - lab_id：实验室 ID
    - video_id：视频唯一 ID
    - frames_per_second：帧率，25~50 fps
    - pix_per_cm_approx：像素到厘米换算率
    - video_duration_sec 视频时长
    - video_width/height：视频分辨率
    - arena_width_cm/height_cm/arena_shape/type：实验场地尺寸/形状
    - tracking_method：追踪方法，如 DeepLabCut
    - body_parts_tracked：JSON 字符串，列出追踪的关键点，如 nose、ear_left 等
    - behaviors_labeled：JSON 字符串，列出该视频标注的行为，如 \["mouse1,self,rear"]
    - mouse\[1-4]\_strain/color/sex/id/age/condition：每只鼠的 品种 / 颜色 / 性别 / ID / 年龄 / 条件
  - 关键点坐标
    - train_tracking/\*.parquet 中每帧（ video_frame ）的每只鼠（ mouse_id，0\~3 或 'mouse0'\~'mouse3' ）每个身体部位（ bodypart，5\~18 个，如 nose、ear_left、tail_base、body_center ）的 (x, y) 坐标（ 像素单位，需归一化到 cm ）
- 目标变量
  - 行为段 agent_id, target_id, action, start_frame, stop_frame
    - agent_id：执行该行为的鼠标的 ID
    - target_id：行为目标小鼠的 ID。某些行为，例如小鼠自我梳理毛发，其主体和目标 ID 相同
    - action：正在发生的行为是什么（ 例如 梳理毛发，追逐 等 ），不同的实验室对不同的行为进行了记录
    - \[start/stop]\_frame：动作的第一帧/最后一帧
- 评估
  - 通过自定义 F-beta（ beta=1，即 F1 ）评估，按实验室平均，支持 overlap 匹配（ 预测覆盖真实段计 TP ），macro 平均所有行为

# 2. 参考思路

- 基于 [baseline](https://www.kaggle.com/code/mattiaangeli/mabe-extra-trees-gpu?scriptVersionId=275125040) 修改，流程 和 大部分步骤 没有改动

#### 2.1 数据预处理

- 按 body_parts_tracked 分组
  - 数据可能是通过 不同跟踪方案 得到的，不同实验室之间的跟踪方案不同，甚至一个实验室内也有多种不同追踪方案
  - 这些数据的 跟踪质量 和 跟踪部位 完全不同，混在一起会严重破坏特征分布，每一组单独处理、单独训练、单独预测
- 过滤无用骨骼点
  - 去掉 headpiece、spine_1/2、tail_middle 等几乎不动的点
  - 减少噪声，降低维度
- 统一单位为 cm
  - 不同视频分辨率差异巨大，必须归一化到物理单位
- 完全 FPS-aware 的时间归一化
  - 所有时间窗口都按真实 FPS 动态缩放：`window_real = round(window_at_30fps × fps / 30)`
  - 解决 “高帧率视频特征被过度平滑” 问题
- 单鼠 和 双鼠 分开建模
  - single 即只用自己的姿态，pair 即只用 agent+target 两个鼠标的相对位姿
  - 行为本质是单体或交互，特征语义完全不同，必须分开
- 特征工程（ 300~400 维 ）
  - 单鼠特征，主要包括
    - 各部位速度、加速度（cm/s、cm/s²）
    - 多尺度速度统计（10/40/160 帧等效时间）
    - 轨迹曲率、转弯率
    - 身体延长率、头部抬高角度
    - 距墙壁/中心距离、历史-未来统计
  - 双鼠特征，主要包括
    - 相对距离、相对速度、相对角度
    - 是否面对面、追逐角度、A 是否在 B 正后方
    - 两鼠速度比、加速度方向一致性
    - 交互区域重叠率、接近趋势（ 正在靠近还是远离 ）

#### 2.2 模型训练

- 每种行为、每个分组、每套超参都单独训练一个模型

  - 每种行为单独训练
    - 将多分类问题分解成多个二分类问题
  - 每个分组单独训练
    - 因为跟踪的部分不同，得到的特征不同，数据分布也不同
  - 每套超参数单独训练

    - 例如 lgbm 有三套超参数组合，分别用来训练拟合不同层次的特征

      ```
      n_estimators=225, learning_rate=0.07, min_child_samples=40,
      num_leaves=31, subsample=0.8, colsample_bytree=0.8

      n_estimators=150, learning_rate=0.1, min_child_samples=20,
      num_leaves=63, max_depth=8, subsample=0.7, colsample_bytree=0.9,
      reg_alpha=0.1, reg_lambda=0.1

      n_estimators=100, learning_rate=0.05, min_child_samples=30,
      num_leaves=127, max_depth=10, subsample=0.75
      ```

    - 总共有 8 套超参数，3 个 lgbm + 2 个 cat + 3 个 xgb

- 自定义 StratifiedSubsetClassifierWEval 处理 自动早停 和 极不平衡场景
  - 耐心轮数设为 训练次数 \* 0.2，并基于 正样本率 动态调整，正样本率过低 则 增大耐心轮数
  - 根据 正样本率 设置不同的 模型评价函数

#### 2.3 后处理

- 预测时加载对应分组的 8 个模型
  - 对每个测试片段，用完全相同的特征工程得到 X_test
  - 保证同分布
- 8 模型概率平均
  - `pred = (pred1 + pred2 + ... + pred8) / 8`，稳定输出
- 时间平滑
  - `pred_smoothed = pred.rolling(5, center=True).mean()` 去抖动
- 自适应阈值（ 每种行为独立 ）
  - 默认 0.27，部分行为调高/低（ 如 mount 0.22，rear 0.32 ）
  - 取 smoothed 后最大概率 ≥ threshold 才触发
  - 解决概率标定问题
- 事件合并 & 最小长度过滤
  - 相邻同行为自动合并，事件长度 < 3 帧直接删除，用于去噪声
- 修复跨视频断裂
  - 如果 stop_frame 正好是视频最后一帧，自动延到 video_max_frame + 1，防止被评分脚本拆成两个事件
- robustify 补全
  - 对所有在 test.csv 中出现、但本方案没预测的（ agent,target,action ）组合，补一个默认事件（ 通常是短的 sniff 或 approach ），防止漏报导致单类 F1=0，拉低平均分

# 3. 核心改动

#### 3.1 数据预处理

- 添加基础特征
  - 将所有得分超过 0.40 的开源方案扔给 gpt，让它分析理解所有方案的特征工程，然后基于当前的 baseline 方案提出优化建议，对每个方案单独进行实验，观察对模型影响

#### 3.2 模型训练

- 统一 StratifiedSubsetClassifierWEval 训练器
  - 原代码问题
    - 代码中存在两种训练器 StratifiedSubsetClassifier 和 StratifiedSubsetClassifierWEval，前者只是一个最基础的训练器，无自动早停 和 应对极不平衡场景的能力
    - 而 8 套不同的超参数，其中只有 3 个使用了 StratifiedSubsetClassifierWEval，另外 5 个 用的都是 StratifiedSubsetClassifier
  - 解决方案
    - 因此将训练器统一为 StratifiedSubsetClassifierWEval
    - 并在 StratifiedSubsetClassifierWEval 中补充训练过程中的日志打印，方便分析优化模型
- 根据学习率设置模型参数
  - 原代码问题
    - 每个模型都需要拟合多个不同的数据，有的正样本率很高（ 23% ），有的正样本率极低（ 0.05% ）
    - 在相同学习率下，根据日志分析
      - 正样本率较低的数据，极其容易拟合，早停机制下，10 轮内就达到了最佳轮数
      - 而正样本率较高的数据，则设置训练轮数跑完也没有完全拟合
  - 解决方案
    - 增大训练轮数
    - 修改耐心轮数，不再基于训练轮数 \* 0.2（ 因为过高 ），固定基础轮数为 30，并保留基于学习率大小，缩放耐心轮数的能力
    - 根据正样本率，动态调整学习率（ 正样本率越低，学习率越低 ）
    - ~~根据正样本率，动态调整 min_child_samples，num_leaves，max_depth【 这三个参数用不同值分别训练是为了分别捕获不同层次的行为规律，并不需要根据正样本率调整 】~~
- 优化训练数据集
  - 原代码问题
    - 原代码从总数据按照正样本比率，抽取出 1500000 行数据进行训练和验证（ 因为 数据量过大，如果用全量数据会爆内存 ）
      - 原代码是多个模型同时训练，因此数据量选的很保守
      - 导致原本正样本就非常稀缺，还浪费了一些正样本数据
  - 解决方案
    - 因为是每套模型参数分别训练，内存压力没有之前严重，因此可以增加数据量至 2000000 行
    - 从原代码中抽出的数据集中，需要包含所有的正样本，避免浪费
- 添加模型
  - 原方案
    - 3 个 lgbm + 2 个 cat + 3 个 xgb，模型类别 不够多样
  - 解决方案
    - 3 个 rf + 3 个 extra + 3 个 gb + 3 个 hgb + 3 个 xgb + 3 个 cat + 3 个 lgbm

#### 3.3 后处理

- 原方案
  - 设置窗口大小为 5 帧，只要窗口存在一个有效值就进行计算，已该 5 桢的平均概率作为行为判断
    ```python
    pred_smoothed = pred.rolling(window=5, min_periods=1, center=True).mean()
    ```
  - 直接设置 0.27 作为阈值，这显然不符合预期，不同实验室的不同行为都应该有不同阈值
- 解决方案

  - 直接用平均概率不恰当

    - ~~极值也是关键的判断依据，需要加大影响力，比如窗口内某一帧行为有比较大把握【 实验发现不如优化后效果 】~~
      ```python
      pred_avg = pred.rolling(window=5, min_periods=1, center=True).mean()
      pred_max = pred.rolling(window=5, min_periods=1, center=True).max()
      pred_min = pred.rolling(window=5, min_periods=1, center=True).min()
      pred_smoothed = 0.6 * pred_avg + 0.2 * pred_max + 0.2 * pred_min
      ```
    - 在上一步的基础上进行优化，虽然增加极值的影响，但是控制过于偏离均值的极值对窗口输出概率的影响

      - 比如可能有一帧概率为 0.99，其他四帧概率为 0.01，那么这个 0.99 很可能是有误判断，需要减少影响
      - 而如果有一帧概率为 0.4，其他四帧概率是 0.3，那么这个 0.4 的概率就比较可信，可以适当增大影响
      - 因为我们需要根据极值相比平均值的差距，分程度处理对窗口输出的影响

        ```python
        # 增加最大最小值对平滑概率的影响
        pred_avg = pred.rolling(window=5, min_periods=1, center=True).mean()
        pred_max = pred.rolling(window=5, min_periods=1, center=True).max()
        pred_min = pred.rolling(window=5, min_periods=1, center=True).min()

        # 极值偏离平均值，分阶段设置极值影响力
        max_dev = pred_max - pred_avg
        min_dev = pred_avg - pred_min

        high_spike_weight = np.where(
          max_dev < 0.2,
          pred_max,
          np.where(max_dev < 0.4,
            (pred_max + pred_avg) / 2,
            np.where(max_dev < 0.6,
              (pred_max + 2 * pred_avg) / 3,
              np.where(max_dev < 0.8,
                (pred_max + 3 * pred_avg) / 4,
                (pred_max + 4 * pred_avg) / 5
              )
            )
          )
        )

        low_spike_weight = np.where(
          min_dev < 0.2,
          pred_min,
          np.where(min_dev < 0.4,
            (pred_min + pred_avg) / 2,
            np.where(min_dev < 0.6,
              (pred_min + 2 * pred_avg) / 3,
              np.where(min_dev < 0.8,
                (pred_min + 3 * pred_avg) / 4,
                (pred_min + 4 * pred_avg) / 5
              )
            )
          )
        )

        # 基础平滑 + 动态极值增强
        pred_smoothed = 0.5 * pred_avg + 0.25 * high_spike_weight + 0.25 * low_spike_weight
        ```

    - ~~除了尝试增加极值的影响，还可以尝试减小极值的影响【 实验发现效果不如增加极值影响 】~~

      - ~~比如可能有一帧概率为 0.99，其他四帧概率为 0.01，那么平均值会被拉到 0.2 附近，但这并不能代表窗口内大部分帧的判断~~
      - ~~因此，我们可以分程度减少极值对平均值的影响~~

        ```python
        # 增加最大最小值对平滑概率的影响
        pred_avg = pred.rolling(window=5, min_periods=1, center=True).mean()
        pred_max = pred.rolling(window=5, min_periods=1, center=True).max()
        pred_min = pred.rolling(window=5, min_periods=1, center=True).min()

        # 极值偏离平均值，分阶段设置极值影响力
        max_dev = pred_max - pred_avg
        min_dev = pred_avg - pred_min

        punish_high = np.where(
          max_dev < 0.2, 1.0,
          np.where(max_dev < 0.4, 2.0,
          np.where(max_dev < 0.6, 3.0,
          np.where(max_dev < 0.8, 4.0, 5.0))))
        punished_max = pred_avg + (pred_max - pred_avg) / punish_high

        punish_low = np.where(
          min_dev < 0.2, 1.0,
          np.where(min_dev < 0.4, 2.0,
          np.where(min_dev < 0.6, 3.0,
          np.where(min_dev < 0.8, 4.0, 5.0))))
        punished_min = pred_avg - (pred_avg - pred_min) / punish_low

        pred_smoothed = (5 * pred_avg - pred_max - pred_min + punished_max + punished_min) / 5
        ```

  - 网格搜索，尝试 0.00 到 0.99 中间 200 个值，取最优
