## 1. 背景

- 在机器学习中，内存通常比较紧张，常见情况包括
  - 未删除模型引用，训练完成后，模型变量仍然存在
  - 数据预处理缓存未清理
  - 数据加载器 DataLoader 的 worker 进程未正确关闭
  - 可视化工具，TensorBoard 等工具保存了历史数据
  - ensemble 场景，多个模型串行，当上个模型训练完后，内存并没有被清理，导致内存压力越来越大，最终内存溢出
- 因此需要及时清理深度学习 训练 和 推理 过程中占用的 GPU 和 CPU 资源，但也需要避免过于频繁调用清理，会影响性能，因此需要在合适时机调用清理，比如单个模型运行结束时

## 2. 内存清理（ CPU ）

#### 2.1 变量删除

- 当不再需要某个变量时，应该及时删除引用
  ```python
  del model
  ```
- 删除前，可以检查当前作用域中是否存在该变量，常用 locals() 和 globals() 内置方法，分别返回当前局部/全局作用域的符号表（ 字典 ），主要用于调试和查看变量状态

  ```python
  # 在全局作用域中
  x = 10
  y = 20

  # 在全局作用域中，locals() 和 globals() 返回相同的字典
  print("locals() in global:", locals())
  print("globals() in global:", globals())

  def test():
    z = 30
    print("locals() in function:", locals())  # {'z': 30}
    print("globals() in function:", 'x' in globals())  # True
  ```

- 全局 和 局部 变量在编译时已经确定，locals() 和 globals() 返回的是当前作用域变量的快照副本，修改不影响真实变量

  ```python
  def test():
    x = 10
    print("修改前:", locals())  # {'x': 10}

    # 尝试修改 locals()
    locals()['x'] = 20  # 这不会改变实际的 x
    print("x 的值:", x)  # 依然是 10

    # 尝试添加新变量
    locals()['y'] = 30  # 这不会创建 y
    print("locals():", locals())  # {'x': 10}，没有 y

    # 尝试删除变量
    del locals()['x']  # 这不会删除 x
    print("x 还在吗?", 'x' in locals())  # True

  test()
  ```

- 实际使用
  ```python
  # 或者 globals()
  if 'model' in locals():
    del model
  ```

#### 2.2 垃圾回收

- 删除变量并不代表内存被回收，需要执行垃圾回收才能真正释放内存
- python 也是使用分代回收策略，总共分了 3 代，默认触发垃圾回收时机如下

  ```python
  import gc

  print "Garbage collection thresholds: %r" % gc.get_threshold()
  # Garbage collection thresholds: (700, 10, 10)
  # 700：表示当分配对象的个数达到 700 时，进行一次 0 代回收
  # 10：当进行 10 次 0 代回收以后触发一次 1 代回收
  # 10：当进行 10 次 1 代回收以后触发一次 2 代回收

  # 上面这个是默认的回收策略的阈值
  # 也可以自己设置回收策略的阈值
  gc.set_threshold(500, 5, 5)
  ```

- 由于自动垃圾收集高度重视空闲对象的数量，而不是它们的大小，因此当代码中释放占据大量内存的对象时，是运行手动垃圾收集的良好时机（ 注意不要频繁调用，会浪费性能 ）

  ```python
  if 'model' in locals():
    del model

  gc.collect()
  ```

#### 2.3 内存使用情况

- 通常使用 psutil 库来获取系统进程和系统利用率的信息，包括 CPU 内存

  ```python
  import psutil
  import os

  def show_cpu_memory():
    # 获取当前进程
    process = psutil.Process(os.getpid())

    # 当前进程的内存使用
    mem_info = process.memory_info()
    print(f"当前进程:")
    print(f"RSS ( 物理内存 ): {mem_info.rss / 1024**2:.2f} MB")
    print(f"VMS ( 虚拟内存 ): {mem_info.vms / 1024**2:.2f} MB")

    # 更多详细信息
    mem_full = process.memory_full_info()
    if hasattr(mem_full, 'uss'):
      print(f"USS ( 独占内存 ): {mem_full.uss / 1024**2:.2f} MB")

    # 系统整体内存
    system_mem = psutil.virtual_memory()
    print(f"\n系统总内存:")
    print(f"总计: {system_mem.total / 1024**3:.2f} GB")
    print(f"已用: {system_mem.used / 1024**3:.2f} GB")
    print(f"可用: {system_mem.available / 1024**3:.2f} GB")
    print(f"使用率: {system_mem.percent}%")

    # 交换内存（ Swap ）
    swap = psutil.swap_memory()
    print(f"\n交换内存:")
    print(f"总计: {swap.total / 1024**3:.2f} GB")
    print(f"已用: {swap.used / 1024**3:.2f} GB")
    print(f"使用率: {swap.percent}%")

    return mem_info.rss, system_mem.percent
  ```

## 3. 显存清理（ GPU ）

- 示例都以 PyTorch 为例，清理前需要检查是否使用 GPU
  ```python
  if torch.cuda.is_available()
  ```

#### 3.1 清空 GPU 缓存

- 清空 GPU 缓存
  ```python
  torch.cuda.empty_cache()
  ```

#### 3.2 显存使用情况

- 步骤如下
  - 等待所有 CUDA 操作完成
    - GPU 操作异步，不同步时间测量不准确
    - 确保内存统计反映的是已完成操作的状态
  - 重置 CUDA 峰值 和 累计 统计
    - 重置后，显存统计从当前点开始记录，避免历史数据干扰
  - 统计当前 GPU 的 已分配内存 和 保留内存 情况
- 具体代码

  ```python
  # 同步CUDA设备
  torch.cuda.synchronize()
  print("CUDA synchronized ✓")

  # 重置 CUDA 显存统计
  torch.cuda.reset_peak_memory_stats() # 重置峰值显存统计
  torch.cuda.reset_accumulated_memory_stats() # 重置累计显存统计
  print("CUDA memory stats reset ✓")

  # 显示当前GPU内存使用情况
  for i in range(torch.cuda.device_count()):
    allocated = torch.cuda.memory_allocated(i) / 1024**3 # 已分配内存（ GB ）
    reserved = torch.cuda.memory_reserved(i) / 1024**3 # 保留内存（ GB ）
    print(f"  GPU {i}: Allocated: {allocated:.2f} GB, Reserved: {reserved:.2f} GB")
  ```
