## 1. conda

- 安装地址：https://www.anaconda.com/download/

#### 1.1 conda 和 pip 的区别

> conda ≈ pip（ python 包管理 ）+ virtualenv（ 虚拟环境 ）+ 非 python 依赖包管理

- pip 是 Python 包管理工具，conda 是一个开源的软件包管理系统和环境管理系统
- pip 对 Python 包进行管理，而 conda 不仅能进行包管理，还能够创建相互隔离的环境，该环境可以包含不同版本的 Python 和或其中安装的软件包
- pip 下载安装的是 wheels 或 source 的 Python 软件包，而 conda 下载安装的软件包是二进制文件
- pip 安装的是 Python 软件包，而 conda 安装的是可能用任何语言编写的软件包（ 比如可能包含 C 或 C++ 库，R 软件包或任何其他软件 ）
- 使用方式
  ```
  pip install [包名] == [版本号]
  conda install [包名] = [版本号]
  ```

#### 1.2 conda 管理环境常用命令

```
# 查看环境
conda info --env

# 创建环境
conda create --name test python=3.5

# 使用指定环境
conda activate test

# 退出当前环境
conda deactivate

# 删除指定环境
conda remove -n test --all
```

#### 1.3 Anaconda 与 Miniconda

- Anaconda 和 Miniconda 都是 Continuum Analytics 的开源项目，用于管理 Python 的环境和包，两者都有用于创建和管理虚拟环境的 conda 包管理器
- Anaconda 是一个包含了 conda、Python 和超过 150 个科学包及其依赖项的科学 Python 发行版。它具有可视化图形用户界面（ Anaconda Navigator ）并且为了方便新手使用，预先包含了大量的库，如 NumPy, Pandas, Scipy, Matplotlib 等
- 相较之下，Miniconda 更加轻量级。它只包含了 Python 和 Conda，但并没有预装其他的库。Miniconda 用户需要手动安装他们需要的包，这使得 Miniconda 的环境更为简洁，可以根据实际需求来安装必要的包，避免不必要的存储占用

## 2. TensorFlow 和 PyTorch

- TensorFlow 和 PyTorch 是两个功能强大的深度学习框架，分别是 FaceBook 和 Google 的开发的，它们在运算模式、使用对象、灵活性、计算速度、依赖库、数据加载和设备管理等方面存在一些不同
- 选择哪个框架取决于具体的需求和使用场景。如果注重计算效率和大规模模型训练，TensorFlow 可能更适合；如果注重灵活性和开发速度，PyTorch 可能更适合

#### 2.1 两者区别

- 运算模式
  - TensorFlow 是一个静态图计算框架，它使用计算图来表示计算过程。在 TensorFlow 中，首先需要定义计算图，然后将数据传递给图中的节点进行计算。这种静态图的方式可以提高计算效率，特别适用于大规模的模型训练
  - 相比之下，PyTorch 是一个动态图计算框架，它允许用户在运行时进行计算图的构建和修改。这种动态图的方式使得模型的调试和开发更加灵活和直观
- 使用对象
  - TensorFlow 使用张量（ Tensor ）作为主要的数据结构，张量是多维数组的扩展。TensorFlow 的 API 设计更加面向对象，用户需要通过创建和操作张量来构建计算图
  - PyTorch 则使用张量和变量（ Variable ）作为主要的数据结构。变量是对张量的封装，除了存储数据外，还包含了梯度等附加信息。PyTorch 的 API 设计更加直观和 Pythonic，用户可以像使用普通的 Python 变量一样使用张量和变量
- 灵活性
  - 由于 PyTorch 是动态图计算框架，它在模型的构建和调试方面更加灵活。用户可以使用 Python 的控制流语句和标准库函数来定义模型，从而更容易实现复杂的模型结构和算法
  - TensorFlow 的静态图计算模式在某些情况下可能会限制模型的灵活性。虽然 TensorFlow 提供了一些高级 API（ 如 Keras ）来简化模型的构建过程，但相比之下，PyTorch 更适合于研究和原型开发阶段
- 计算速度
  - 由于 TensorFlow 使用静态图计算模式，它可以在计算图的优化和并行化方面进行更多的优化，从而实现更高的计算效率。在大规模模型和数据集上，TensorFlow 通常比 PyTorch 更快
  - 然而对于小规模模型和中小型数据集，PyTorch 的动态图计算模式可能会更快，因为它可以更好地利用硬件资源和内存
- 依赖库
  - TensorFlow 使用 C++ 作为后端，可以支持多种编程语言（ 如 Python、C++、Java 等 ）进行开发
  - PyTorch 则使用 C++ 和 Python 混合开发，主要以 Python 为主
- 数据加载
  - TensorFlow 提供了 tf.data API 来处理和预处理数据，可以高效地进行数据管道的构建和扩展
  - PyTorch 则使用 torch.utils.data 模块来加载和处理数据。它提供了一些方便的工具和函数来处理常见的数据加载任务
- 设备管理
  - TensorFlow 使用设备分配策略（ Device Placement ）来管理计算资源的分配，可以将计算任务分配到不同的设备上进行并行计算
  - PyTorch 则使用 torch.device 来管理设备，用户可以轻松地指定模型和张量在哪个设备上进行计算，如 CPU 或 GPU

## 3. Pandas 和 Polars

#### 3.1 两者差异

- 两者对比
  - 和 Pandas 相比，Polars 的速度更快，执行常见运算的速度是 Pandas 的 5 到 10 倍。
  - 另外 Polars 运算的内存需求也明显小于 Pandas，Pandas 需要数据集大小的 5 到 10 倍左右的 RAM 来执行运算，而 Polars 需要 2 到 4 倍
  - 但是 Pandas 更成熟，社区支持更好，与其他库的集成也更好
- Polars 更优异的原因：
  - 以 Rust 编写从 0 编写
    - 没有扩展依赖，低级语言速度快
    - 使用 Rust 的另一个优点是它允许安全并发，使并行性尽可能可预测。这意味着 Polars 可以安全使用所有机器核心执行涉及多个列的复杂查询
  - 基于 Apache Arrow 上构建数据库，一种独立于语言的内存格式
  - 查询优化
    - Polars 性能的另一个核心是评估代码的方式。Pandas 默认使用 Eager 执行，按照编写的顺序执行运算。相比之下，Polars 能够同时执行 Eager 和惰性执行，查询优化器将对所有必需运算求值并制定最有效的代码执行方式。这可能包括重写运算的执行顺序或删除冗余计算
  - 表达性 API
    - Polars 拥有一个极具表达性的 API，基本上想执行的任何运算都可以用 Polars 方法表达
    - 相比之下，pandas 中更复杂的运算通常需要作为 lambda 表达式传递给 apply 方法。apply 方法的问题是它循环遍历 DataFrame 的行，对每一行按顺序执行运算。内置方法能够在列级别上工作并利用另一种称为 SIMD 的并行形式

#### 3.2 运行时间对比

- 数据读取

  ```python
  # train.parquet: 2.35G

  train_pd = pd.read_parquet('/Users/Downloads/archive/train.parquet') #Pandas dataframe
  train_pl = pl.read_parquet('/Users/Downloads/archive/train.parquet') #Polars dataframe

  # CPU times: user 3.85 s, sys: 8.69 s, total: 12.5 s
  # Wall time: 10.4 s
  # CPU times: user 3.07 s, sys: 2.22 s, total: 5.29 s
  # Wall time: 3.39 s
  ```

- 聚合操作

  ```python
  # pandas query

  nums = ["num_7", "num_8", "num_9", "num_10", "num_11", "num_12", "num_13", "num_14", "num_15"]
  cats = ["cat_1", "cat_2", "cat_3", "cat_4", "cat_5", "cat_6"]
  train_pd[nums].agg(['min','max','mean','median','std'])

  # Polars query

  train_pl.with_columns([
    pl.col(nums).min().suffix('_min'),
    pl.col(nums).max().suffix('_max'),
    pl.col(nums).mean().suffix('_mean'),
    pl.col(nums).median().suffix('_median'),
    pl.col(nums).std().suffix('_std'),
  ])

  # CPU times: user 6.06 s, sys: 4.19 s, total: 10.3 s
  # Wall time: 15.8 s
  # CPU times: user 4.51 s, sys: 5.49 s, total: 10 s
  # Wall time: 8.09 s
  ```

- 查询后计算

  ```python
  # Pandas filter and select

  train_pd[train_pd['cat_1']==1][nums].mean()

  # Polars filter and select

  train_pl.filter(pl.col("cat_1") == 1).select(pl.col(nums).mean())

  # CPU times: user 730 ms, sys: 1.65 s, total: 2.38 s
  # Wall time: 4.24 s
  # CPU times: user 659 ms, sys: 3.22 s, total: 3.88 s
  # Wall time: 2.12 s
  ```

- 分类再聚合

  ```python
  Function_3 = train_pd.groupby(['user'])[nums].agg('mean')
  Function_3 = train_pl.groupby('user').agg(pl.col(nums).mean())

  # CPU times: user 2.4 s, sys: 938 ms, total: 3.33 s
  # Wall time: 3.46 s
  # CPU times: user 6.92 s, sys: 2.68 s, total: 9.6 s
  # Wall time: 1.78 s
  ```

- 排序

```python
cols=['user','num_8'] # columns to be used for sorting

# Sorting in Pandas

a = train_pd.sort_values(by=cols,ascending=True)

#Sorting in Polars

b = train_pl.sort(cols,descending=False)

# CPU times: user 31.9 s, sys: 7.28 s, total: 39.2 s
# Wall time: 46.2 s
# CPU times: user 32.2 s, sys: 7.04 s, total: 39.2 s
# Wall time: 11.6 s
```
