## 1. conda

- 安装地址：https://www.anaconda.com/download/

#### 1.1 conda 和 pip 的区别

> conda ≈ pip（ python 包管理 ）+ virtualenv（ 虚拟环境 ）+ 非 python 依赖包管理

- pip 是 Python 包管理工具，conda 是一个开源的软件包管理系统和环境管理系统
- pip 对 Python 包进行管理，而 conda 不仅能进行包管理，还能够创建相互隔离的环境，该环境可以包含不同版本的 Python 和或其中安装的软件包
- pip 下载安装的是 wheels 或 source 的 Python 软件包，而 conda 下载安装的软件包是二进制文件
- pip 安装的是 Python 软件包，而 conda 安装的是可能用任何语言编写的软件包（ 比如可能包含 C 或 C++ 库，R 软件包或任何其他软件 ）
- 使用方式
  ```
  pip install [包名] == [版本号]
  conda install [包名] = [版本号]
  ```

#### 1.2 conda 管理环境常用命令

```
# 查看环境
conda info --env

# 创建环境
conda create --name test python=3.5

# 使用指定环境
conda activate test

# 退出当前环境
conda deactivate

# 删除指定环境
conda remove -n test --all
```

#### 1.3 Anaconda 与 Miniconda

- Anaconda 和 Miniconda 都是 Continuum Analytics 的开源项目，用于管理 Python 的环境和包，两者都有用于创建和管理虚拟环境的 conda 包管理器
- Anaconda 是一个包含了 conda、Python 和超过 150 个科学包及其依赖项的科学 Python 发行版。它具有可视化图形用户界面（ Anaconda Navigator ）并且为了方便新手使用，预先包含了大量的库，如 NumPy, Pandas, Scipy, Matplotlib 等
- 相较之下，Miniconda 更加轻量级。它只包含了 Python 和 Conda，但并没有预装其他的库。Miniconda 用户需要手动安装他们需要的包，这使得 Miniconda 的环境更为简洁，可以根据实际需求来安装必要的包，避免不必要的存储占用

## 2. TensorFlow 和 PyTorch

- TensorFlow 和 PyTorch 是两个功能强大的深度学习框架，分别是 FaceBook 和 Google 的开发的，它们在运算模式、使用对象、灵活性、计算速度、依赖库、数据加载和设备管理等方面存在一些不同。选择哪个框架取决于具体的需求和使用场景。如果注重计算效率和大规模模型训练，TensorFlow 可能更适合；如果注重灵活性和开发速度，PyTorch 可能更适合

#### 2.1 两者区别

- 运算模式
  - TensorFlow 是一个静态图计算框架，它使用计算图来表示计算过程。在 TensorFlow 中，首先需要定义计算图，然后将数据传递给图中的节点进行计算。这种静态图的方式可以提高计算效率，特别适用于大规模的模型训练
  - 相比之下，PyTorch 是一个动态图计算框架，它允许用户在运行时进行计算图的构建和修改。这种动态图的方式使得模型的调试和开发更加灵活和直观
- 使用对象
  - TensorFlow 使用张量（ Tensor ）作为主要的数据结构，张量是多维数组的扩展。TensorFlow 的 API 设计更加面向对象，用户需要通过创建和操作张量来构建计算图
  - PyTorch 则使用张量和变量（ Variable ）作为主要的数据结构。变量是对张量的封装，除了存储数据外，还包含了梯度等附加信息。PyTorch 的 API 设计更加直观和 Pythonic，用户可以像使用普通的 Python 变量一样使用张量和变量
- 灵活性
  - 由于 PyTorch 是动态图计算框架，它在模型的构建和调试方面更加灵活。用户可以使用 Python 的控制流语句和标准库函数来定义模型，从而更容易实现复杂的模型结构和算法
  - TensorFlow 的静态图计算模式在某些情况下可能会限制模型的灵活性。虽然 TensorFlow 提供了一些高级 API（ 如 Keras ）来简化模型的构建过程，但相比之下，PyTorch 更适合于研究和原型开发阶段
- 计算速度
  - 由于 TensorFlow 使用静态图计算模式，它可以在计算图的优化和并行化方面进行更多的优化，从而实现更高的计算效率。在大规模模型和数据集上，TensorFlow 通常比 PyTorch 更快
  - 然而对于小规模模型和中小型数据集，PyTorch 的动态图计算模式可能会更快，因为它可以更好地利用硬件资源和内存
- 依赖库
  - TensorFlow 使用 C++ 作为后端，可以支持多种编程语言（ 如 Python、C++、Java 等 ）进行开发
  - PyTorch 则使用 C++ 和 Python 混合开发，主要以 Python 为主
- 数据加载
  - TensorFlow 提供了 tf.data API 来处理和预处理数据，可以高效地进行数据管道的构建和扩展
  - PyTorch 则使用 torch.utils.data 模块来加载和处理数据。它提供了一些方便的工具和函数来处理常见的数据加载任务
- 设备管理
  - TensorFlow 使用设备分配策略（ Device Placement ）来管理计算资源的分配，可以将计算任务分配到不同的设备上进行并行计算
  - PyTorch 则使用 torch.device 来管理设备，用户可以轻松地指定模型和张量在哪个设备上进行计算，如 CPU 或 GPU

## 3. Pandas 和 Polars

#### 3.1 两者差异

- 和 Pandas 相比，Polars 的速度更快，执行常见运算的速度是 Pandas 的 5 到 10 倍。 另外 Polars 运算的内存需求也明显小于 Pandas，Pandas 需要数据集大小的 5 到 10 倍左右的 RAM 来执行运算，而 Polars 需要 2 到 4 倍，但是 Pandas 更成熟，社区支持更好，与其他库的集成也更好
- Polars 更优异的原因：
  - 以 Rust 编写从 0 编写，没有扩展依赖，低级语言速度快。使用 Rust 的另一个优点是它允许安全并发，使并行性尽可能可预测。这意味着 Polars 可以安全使用所有机器核心执行涉及多个列的复杂查询
  - 基于 Apache Arrow 上构建数据库，一种独立于语言的内存格式
  - 查询优化，Polars 性能的另一个核心是评估代码的方式。Pandas 默认使用 Eager 执行，按照编写的顺序执行运算。相比之下，Polars 能够同时执行 Eager 和惰性执行，查询优化器将对所有必需运算求值并制定最有效的代码执行方式。这可能包括重写运算的执行顺序或删除冗余计算
  - 表达性 API，Polars 拥有一个极具表达性的 API，基本上您想执行的任何运算都可以用 Polars 方法表达。相比之下，pandas 中更复杂的运算通常需要作为 lambda 表达式传递给 apply 方法。apply 方法的问题是它循环遍历 DataFrame 的行，对每一行按顺序执行运算。内置方法能够在列级别上工作并利用另一种称为 SIMD 的并行形式

#### 3.2 运行时间对比

- 数据读取

  ```python
  # train.parquet: 2.35G

  train_pd = pd.read_parquet('/Users/Downloads/archive/train.parquet') #Pandas dataframe
  train_pl = pl.read_parquet('/Users/Downloads/archive/train.parquet') #Polars dataframe

  # CPU times: user 3.85 s, sys: 8.69 s, total: 12.5 s
  # Wall time: 10.4 s
  # CPU times: user 3.07 s, sys: 2.22 s, total: 5.29 s
  # Wall time: 3.39 s
  ```

- 聚合操作

  ```python
  # pandas query

  nums = ["num_7", "num_8", "num_9", "num_10", "num_11", "num_12", "num_13", "num_14", "num_15"]
  cats = ["cat_1", "cat_2", "cat_3", "cat_4", "cat_5", "cat_6"]
  train_pd[nums].agg(['min','max','mean','median','std'])

  # Polars query

  train_pl.with_columns([
    pl.col(nums).min().suffix('_min'),
    pl.col(nums).max().suffix('_max'),
    pl.col(nums).mean().suffix('_mean'),
    pl.col(nums).median().suffix('_median'),
    pl.col(nums).std().suffix('_std'),
  ])

  # CPU times: user 6.06 s, sys: 4.19 s, total: 10.3 s
  # Wall time: 15.8 s
  # CPU times: user 4.51 s, sys: 5.49 s, total: 10 s
  # Wall time: 8.09 s
  ```

- 查询后计算

  ```python
  # Pandas filter and select

  train_pd[train_pd['cat_1']==1][nums].mean()

  # Polars filter and select

  train_pl.filter(pl.col("cat_1") == 1).select(pl.col(nums).mean())

  # CPU times: user 730 ms, sys: 1.65 s, total: 2.38 s
  # Wall time: 4.24 s
  # CPU times: user 659 ms, sys: 3.22 s, total: 3.88 s
  # Wall time: 2.12 s
  ```

- 分类再聚合

  ```python
  Function_3 = train_pd.groupby(['user'])[nums].agg('mean')
  Function_3 = train_pl.groupby('user').agg(pl.col(nums).mean())

  # CPU times: user 2.4 s, sys: 938 ms, total: 3.33 s
  # Wall time: 3.46 s
  # CPU times: user 6.92 s, sys: 2.68 s, total: 9.6 s
  # Wall time: 1.78 s
  ```

- 排序

```python
cols=['user','num_8'] # columns to be used for sorting

# Sorting in Pandas

a = train_pd.sort_values(by=cols,ascending=True)

#Sorting in Polars

b = train_pl.sort(cols,descending=False)

# CPU times: user 31.9 s, sys: 7.28 s, total: 39.2 s
# Wall time: 46.2 s
# CPU times: user 32.2 s, sys: 7.04 s, total: 39.2 s
# Wall time: 11.6 s
```

## 4. 基础名词

#### 4.1 人工智能（ Artificial Intelligence，AI ）

- 通常将人工智能分为弱人工智能和强人工智能，前者让机器具备观察和感知的能力，可以做到一定程度的理解和推理，而强人工智能让机器获得自适应能力，解决一些之前没有遇到过的问题
- 目前的科研工作都集中在弱人工智能这部分，强人工智能还未实现
- 人工智能的研究领域也在不断扩大，包括机器学习，自然语言处理，人机交互，语音识别，计算机视觉等
- 人工智能 = 算法/模型 + 数据
  ![image](https://github.com/jianyi-gronk/jianyi-gronk/assets/95062803/573d46ec-121a-47ba-9d28-3fd7c553b15b)

#### 4.2 机器学习（ machine learning ）

- 研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善
- 机器学习算法可以分为监督学习、无监督学习、半监督学习、深度学习和强化学习

#### 4.3 监督学习（ supervised learnin ）

- 监督学习是指学习从 x（ 输入 ）到 y（ 输出 ） 的算法（ 函数 ），核心是需要提供带有正确答案的示例（ 正确的 x -> y，也叫训练集 ），通过大量示例，算法最终学会只需要 x，便能得出 y 的能力
- 监督学习主要分为回归和分类
  - 回归：从无限可能的数字中预测数字，例如预测房价，可能是 100，可能是 500，可能是 800
  - 分类：从有限的可能去预测，例如预测下一次的骰子的值

#### 4.4 无监督学习（ unsupervised learning ）

- 无监督学习中，数据只带有输入 x，没带有标签 y（ 即都是没有正确答案的数据 ）
- 无监督学习主要是聚类算法，将没有标签的相似数据自动分组到集群中，比如用于市场细分
- 还有两种其他场景，异常检测，降维
  - 异常检测：用于检测异常事件，比如金融系统中的异常交易
  - 降维：将大数据集压缩成小得多的数据集，同时丢失尽可能少的信息

#### 4.5 神经网络（ neural network，NNs ）

- 神经网络是一种运算模型，由大量的节点（ 或称神经元 ）和之间相互联接构成
- 每个节点代表一种特定的输出函数，称为激励函数（ activation function ）。每两个节点间的连接都代表一个对于通过该连接信号的加权值，称之为权重，这相当于神经网络的记忆
- 网络的输出则依网络的连接方式，权重值和激励函数的不同而不同。而网络自身通常都是对自然界某种算法或者函数的逼近，也可能是对一种逻辑策略的表达
- 常见神经网络算法有：CNN（ 卷积神经网络 ）、RNN（ 循环神经网络 ）、Transformer（ 注意力机制 ）等

#### 4.6 深度学习（ deep learning ）

- 深度学习是神经网络的一种，是指隐藏层非常多的神经网络，也叫深度神经网络
- 深度神经网络可大致理解为包含多个隐含层的神经网络结构。为了提高深层神经网络的训练效果，人们对神经元的连接方法和激活函数等方面做出相应的调整

#### 4.7 大模型（ large model，也称基础模型，即 foundation model ）

- 大模型的原理是基于具有大规模参数和复杂计算结构的深度学习，它利用大量的数据和计算资源来训练具有大量参数的神经网络模型。通过不断地调整模型参数，使得模型能够在各种任务中取得最佳表现，这些模型通常由深度神经网络构建而成，拥有数十亿甚至数千亿个参数
- 大模型通常关注的是对输入图像、语音或特征的映射和识别能力，旨在提高对输入数据的感知和理解能力，通过训练海量数据来学习复杂的模式和特征，具有更强大的泛化能力，可以对未见过的数据做出准确的预测
- 大模型通常采用卷积神经网络（ CNN ）、循环神经网络（ RNN ）或变种网络（ 例如 ResNet、Inception 等 ）进行建模和训练。这些模型的训练通常采用监督学习的方式，通过大量的标注数据进行模型的训练和优化。大模型的训练通常需要大量的计算资源和时间，但一旦训练完成，可以应用于各种相关领域的任务中，具有很好的泛化能力
- 大模型的设计目的是为了提高模型的表达能力和预测性能，能够处理更加复杂的任务和数据。大模型在各种领域都有广泛的应用，包括自然语言处理、计算机视觉、语音识别和推荐系统等

#### 4.8 自然语言处理（ natural language processing，NLP ）

- 自然语言处理是一种机器学习技术，使计算机能够解读、处理和理解人类语言
- 如今有来自各种通信渠道（ 例如电子邮件、短信、社交媒体新闻源、视频、音频 ）的大量语音和文本数据，可以使用 NLP 软件自动处理这些数据，分析消息中的意图或情绪，并实时响应人际沟通
- 主要用途包括机器翻译、舆情监测、自动摘要、观点提取、文本分类、问题回答、文本语义对比、语音识别、中文 OCR 等方面
- 常见的是基于深度学习的自然语言处理技术，在自然语言处理中需应用深度学习模型，如卷积神经网络、循环神经网络等，通过对生成的词向量进行学习，以完成自然语言分类、理解的过程。与传统的机器学习相比，基于深度学习的自然语言处理技术具备以下优势：
  - 深度学习能够以词或句子的向量化为前提，不断学习语言特征，掌握更高层次、更加抽象的语言特征，满足大量特征工程的自然语言处理要求
  - 深度学习无需专家人工定义训练集，可通过神经网络自动学习高层次特征

#### 4.9 大语言模型（ large language model，LLM ）

- 大语言模型通常采用 Transformer 或其变种网络进行建模和训练。这些模型的训练采用预训练的方式，通过大规模的无标注数据进行模型的预训练和初始化。大语言模型的训练需要大量的计算资源和时间，但一旦预训练完成，可以在各种自然语言处理任务上进行微调，以实现高效的自然语言理解和生成
- 大语言模型则更加关注对自然语言文本的语义和上下文的理解能力，旨在实现更准确的语言理解和生成

#### 4.10 计算机视觉（ computer vision，CV ）

- 让计算机和系统能够从图像、视频和其他视觉输入中获取有意义的信息，并根据该信息采取行动或提供建议
- 主要处理的方面有：
  - 识别：比如基于内容的图像提取，姿态评估，光学字符识别
  - 运动：基于序列图像的对物体运动的监测包含多种类型，比如自体运动，图像跟踪
  - 图像恢复：图像恢复的目标在于移除图像中的噪声，例如仪器噪声、动态模糊
  - 场景重建：给定一个场景的二或多幅图像或者一段录像，场景重建寻求为该场景建立一个三维模型。最简单的情况便是生成一组三维空间中的点。更复杂的情况下会建立起完整的三维表面模型
