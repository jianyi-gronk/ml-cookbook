## 1. 人工智能（ Artificial Intelligence，AI ）

- 通常将人工智能分为弱人工智能和强人工智能
  - 前者让机器具备观察和感知的能力，可以做到一定程度的理解和推理
  - 后者让机器获得通用的问题解决能力、学习能力和理解能力，解决之前没有遇到过的问题
- 目前的科研工作都集中在弱人工智能这部分，强人工智能还未实现
- 人工智能的研究领域也在不断扩大，包括机器学习，自然语言处理，人机交互，语音识别，计算机视觉等
- 人工智能（ AI ） = 算法/模型（ Code ） + 数据（ Data ）

## 2. 机器学习（ machine learning ）

- 研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善
- 机器学习算法按数据标签的可用性划分，可以分为 监督学习、无监督学习、半监督学习

#### 2.1 监督学习（ supervised learning ）

- 监督学习是指学习从 x（ 输入 ）到 y（ 输出 ） 的算法（ 函数 ），核心是需要提供带有正确答案的示例（ 正确的 x -> y，也叫训练集 ），通过大量示例，算法最终学会只需要 x，便能得出 y 的能力
- 监督学习主要分为回归和分类
  - 回归：从无限可能的数字中预测数字，例如预测房价，可能是 100，可能是 500，可能是 800
  - 分类：从有限的可能去预测，例如预测下一次的骰子的值

#### 2.2 无监督学习（ unsupervised learning ）

- 无监督学习中，数据只带有输入 x，没带有标签 y（ 即都是没有正确答案的数据 ）
- 无监督学习主要应用以下场景
  - 聚类：将没有标签的相似数据自动分组到集群中，比如用于市场细分
  - 异常检测：用于检测异常事件，比如金融系统中的异常交易
  - 降维：将大数据集压缩成小得多的数据集，同时丢失尽可能少的信息

#### 2.3 半监督学习（ semi-supervised learning ）

- 半监督学习是指同时使用少量带标签数据（ 输入 x 和正确输出 y ）和大量未标签数据（ 只有输入 x ）进行训练的算法
- 核心是通过未标记数据揭示数据内在结构，辅助提升模型性能（ 尤其在标注数据稀缺的场景 ）
- 半监督学习主要应用于以下场景：
  - 半监督分类：增强有限标签数据的分类能力，例如医疗影像诊断中，用 少量医生标注 + 大量未标注 CT 扫描训练疾病分类模型
  - 半监督聚类（ 约束聚类 ）：用少量标签引导无监督聚类，例如电商用户分组时，用已知 VIP 用户信息优化整体客户分群
  - 半监督异常检测：结合少量已知异常样本与大量正常数据，提升检测精度，如网络入侵检测系统

## 3. 神经网络（ neural network，NNs ）

- 神经网络是一种运算模型，由大量的节点（ 或称神经元 ）和之间相互联接构成
- 每个节点代表一种特定的输出函数，称为激活函数（ activation function ）。每两个节点间的连接都代表一个对于通过该连接信号的加权值，称之为权重，这相当于神经网络的记忆
- 网络的输出则依网络的连接方式，权重值和激励函数的不同而不同。而网络自身通常都是对自然界某种算法或者函数的逼近，也可能是对一种逻辑策略的表达
- 常见神经网络算法有：CNN（ 卷积神经网络 ）、RNN（ 循环神经网络 ）、Transformer（ 注意力机制 ）等

#### 3.1 深度学习（ deep learning ）

- 深度学习是基于深层神经网络（ 通常 >= 5 层 ）的机器学习方法，核心是通过层级特征提取实现端到端学习
- 深度神经网络可大致理解为包含多个隐含层的神经网络结构。为了提高深层神经网络的训练效果，人们对神经元的连接方法和激活函数等方面做出相应的调整

#### 3.2 大模型（ large model，也称基础模型，即 foundation model ）

- 大模型指在超大规模数据上预训练、可适应多种下游任务的通用模型：
  - 架构：通常由深度神经网络构建而成，一般以 Transformer 为核心（ 如 GPT-3、PaLM ）
  - 训练范式：
    - 预训练：自监督学习（ 利用无标注数据学习通用表征 ）
    - 微调：监督学习/提示工程（ 用少量标注数据适配具体任务 ）
  - 核心价值：通过大规模参数（ 百亿~万亿级 ）捕获复杂数据模式，增强从样本的学习能力

#### 3.3 自然语言处理（ natural language processing，NLP ）

- 自然语言处理是一种机器学习技术，使计算机能够解读、处理和理解人类语言
- 如今有来自各种通信渠道（ 例如电子邮件、短信、社交媒体新闻源、视频、音频 ）的大量语音和文本数据，可以使用 NLP 软件自动处理这些数据，分析消息中的意图或情绪，并实时响应人际沟通
- 主要用途包括机器翻译、舆情监测、自动摘要、观点提取、文本分类、问题回答、文本语义对比、语音识别、中文 OCR 等方面
- 常见的是基于深度学习的自然语言处理技术，在自然语言处理中需应用深度学习模型，如卷积神经网络、循环神经网络等，通过对生成的词向量进行学习，以完成自然语言分类、理解的过程。与传统的机器学习相比，基于深度学习的自然语言处理技术具备以下优势：
  - 深度学习能够以词或句子的向量化为前提，不断学习语言特征，掌握更高层次、更加抽象的语言特征，满足大量特征工程的自然语言处理要求
  - 深度学习无需专家人工定义训练集，可通过神经网络自动学习高层次特征
  - 2017 年后，基于 Transformer 的模型（ 如 BERT ）取代 CNN/RNN 成为 NLP 主流，因其能建模长距离依赖和双向上下文

#### 3.4 大语言模型（ large language model，LLM ）

- 大语言模型通常采用 Transformer 或其变种网络进行建模和训练。这些模型的训练采用预训练的方式，通过大规模的无标注数据进行模型的预训练和初始化。大语言模型的训练需要大量的计算资源和时间，但一旦预训练完成，可以在各种自然语言处理任务上进行微调，以实现高效的自然语言理解和生成
- 大语言模型则更加关注对自然语言文本的语义和上下文的理解能力，旨在实现更准确的语言理解和生成

#### 3.5 计算机视觉（ computer vision，CV ）

- 让计算机和系统能够从图像、视频和其他视觉输入中获取有意义的信息，并根据该信息采取行动或提供建议
- 主要处理的方面有：
  - 识别：比如基于内容的图像提取，姿态评估，光学字符识别
  - 运动：基于序列图像的对物体运动的监测包含多种类型，比如自体运动，图像跟踪
  - 图像恢复：图像恢复的目标在于移除图像中的噪声，例如仪器噪声、动态模糊
  - 场景重建：给定一个场景的二或多幅图像或者一段录像，场景重建寻求为该场景建立一个三维模型。最简单的情况便是生成一组三维空间中的点。更复杂的情况下会建立起完整的三维表面模型

#### 3.6 计算机听觉（ computer audition，CA ）

- 计算机听觉是研究如何让计算机系统理解、分析和生成音频信号的技术领域，旨在使机器具备类人的听觉感知能力
- 核心任务包括：
  - 语音识别（ ASR ）：将语音信号转换为文本，例如智能语音助手（ Siri/Alexa ）的指令识别
  - 声纹识别：通过声音特征识别说话人身份，应用于安全认证和刑侦分析
  - 音频事件检测：识别环境声音中的特定事件，如玻璃破碎、枪声等安防场景
- 关键技术方法：
  - 传统方法：梅尔频率倒谱系数（ MFCC ）、滤波器组等手工特征提取 + 隐马尔可夫模型（ HMM ）
  - 深度学习方法：
    - 卷积神经网络（ CNN ）：处理频谱图特征（ 如 VGGish 模型 ）
    - 循环神经网络（ RNN ）：建模音频时序依赖（ 如 LSTM 语音识别 ）
    - Transformer 架构：处理长序列音频（ 如 Whisper 语音识别系统 ）
    - 生成对抗网络（ GAN）：合成逼真语音或音乐（ 如 WaveGAN ）
