## 1. 题目介绍

- [题目](https://www.kaggle.com/competitions/playground-series-s5e3)：测每日降雨的概率
- 数据集：由 2189 条数据，11 个特征组成，包含 日期，温度，最高最低温度 等
- 输出：预测下雨的概率，二分类问题
- 评估：通过 AUC-ROC 评估

## 2. 大佬方案

- [思路](https://www.kaggle.com/competitions/playground-series-s5e3/discussion/571176)

#### 2.1 数据预处理

- 观察数据集描述，该数据集是由 366 个的原始数据集，通过数据增强生成的 2189 条数据，所以它本质仍然只有 366 条数据的信息，核心即 **不能仅通过应用数据增强来生成更多数据来假装小数据就是大数据**，因此这样看，11 个特征是充足的，**不需要在特征工程添加特征**
- 将原始的 366 条数据并入到数据集中，用来 **丰富数据集**

#### 2.2 模型多样性构建

- 模型间预测误差的独立性越高，集成效果越好
- GBDT 类模型（ XGBoost，CatBoost ）
  - 擅长捕捉特征间的非线性关系，采用浅层树（ max_depth=3 ）与正则化（ colsample_bytree=0.9 ）防止过拟合
- 神经网络（ TabPFN ）
  - 基于预训练的 Transformer 架构，适用于小样本表格数据，无需特征工程自动学习特征交互
  - **少量数据的情况，仍然适用于神经网络**，可以通过减少可训练参数（ 如隐藏层节点数、层数 ）降低模型复杂度，缓解过拟合，极端情况下，单层线性神经网络（ 无隐藏层 ）等价于 线性回归/逻辑回归
- 支持向量机（ RAPIDS SVC ）
  - 使用多项式核（ kernel='poly', degree=1 ）近似线性分类，提升对噪声的鲁棒性

#### 2.3 模型评估

- **交叉验证的时候，按照年份划分**，而不是随机从中挑选数据，模拟测试集为未来新年份数据的时间序列特性

#### 2.4 模型集成

- **小数据更适合等权重的集成**
  - 即强制公平性，每个模型必须独立有效，避免依赖“幸运”模型。
  - 举例：原始方案中，添加新 Model 后仅当其本身有效时，等权重集成（ 较大比例 ）才会提升性能
  - 对比：若允许 0.01% 权重，即使新 Model 无效，也可能因随机性提升 CV 分数（ 虚假提升 ）
- 而大数据适合探索权重比例
  - 举例：训练数据 100 万行，验证集 10 万行，此时模型性能评估的方差显著降低，噪声影响减弱
  - 策略：可安全分配极小权重（ 如 1% ）给新模型，因其对整体预测影响微弱但可能带来稳定增益
  - 因为当样本量 n→∞ 时，模型性能估计趋近真实值。此时权重优化可基于可靠评估
