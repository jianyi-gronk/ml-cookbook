## 6. 正则化（ Regularization ）

#### 6.1 核心目的

- **解决过拟合问题**：当模型过度拟合训练数据噪声时，正则化通过约束参数大小提升泛化能力
- **控制模型复杂度**：在代价函数中添加惩罚项，防止权重过大
- **提高数值稳定性**：尤其对解析解法中矩阵不可逆的情况提供解决方案

#### 6.2 正则化方法

- 正则化在线性回归代价函数中添加权重惩罚项，常用的正则化有 L1 和 L2
- **L1 正则化（ Lasso 回归 ）**
  $$J(\mathbf{w}, b) = \frac{1}{2m} \left[ \sum_{i=1}^{m} (f_{\mathbf{w},b}(\mathbf{x}^{(i)}) - y^{(i)})^2 + \lambda \sum_{j=1}^{n} |w_j| \right]$$
- **L2 正则化（ Ridge 回归，也叫 岭回归 ）**
  $$J(\mathbf{w}, b) = \frac{1}{2m} \left[ \sum_{i=1}^{m} (f_{\mathbf{w},b}(\mathbf{x}^{(i)}) - y^{(i)})^2 + \lambda \sum_{j=1}^{n} w_j^2 \right]$$
- $\lambda$：**正则化系数**，是可设置的超参数，控制惩罚强度
  - $\lambda = 0$：退化为标准线性回归
  - $\lambda \to \infty$：所有权重趋近于零
- 注意：**偏置项 $b$ 通常不被正则化**

#### 6.3 正则化对解法的影响

- 梯度下降的修改
  - L1 正则化 的权重更新
    $$w_j = w_j - \alpha \left[ \frac{1}{m} \sum_{i=1}^{m} (f_{\mathbf{w},b}(\mathbf{x}^{(i)}) - y^{(i)}) x_j^{(i)} + \frac{\lambda}{m} \cdot \text{sign}(w_j) \right]$$
    - 其中 $\text{sign}(w_j)$ 为符号函数
      $$
      \text{sign}(w_j) =
      \begin{cases}
      1 & \text{if } w_j > 0 \\
      0 & \text{if } w_j = 0 \\
      -1 & \text{if } w_j < 0
      \end{cases}
      $$
    - 即每次更新时向零方向施加固定大小的收缩（ 与权重大小无关 ）
  - L2 正则化 的权重更新
    $$w_j = w_j - \alpha \left[ \frac{1}{m} \sum_{i=1}^{m} (f_{\mathbf{w},b}(\mathbf{x}^{(i)}) - y^{(i)}) x_j^{(i)} + \frac{\lambda}{m} w_j \right]$$
    - 即每次更新时额外缩小权重（ 权重衰减 ）
- 解析解法的修改
  - L1 正则化 没有闭式解析解，需使用迭代优化方法（ 如坐标下降、近端梯度法 ）
    $$\min_{\mathbf{w}} \left( \frac{1}{2m} \|\mathbf{y} - \mathbf{X}\mathbf{w}\|^2_2 + \lambda \|\mathbf{w}\|_1 \right)$$
    - 原因：L1 范数的绝对值项在零点不可导
    - 常用解法：最小角回归（ LARS ）、坐标下降法
  - l2 正则化 的正规方程
    $$\mathbf{w} = (\mathbf{X}^T \mathbf{X} + \lambda \mathbf{I})^{-1} \mathbf{X}^T \mathbf{y}$$
    - 其中 $\mathbf{I}$ 是 $(n+1) \times (n+1)$ 单位矩阵
    - **确保 $\mathbf{X}^T\mathbf{X} + \lambda\mathbf{I}$ 恒可逆**（ 解决多重共线性问题 ）
- 总结 L1/L2 更新公式差异
  | 正则化类型 | 更新行为 | 数学特性 | 结果特征 |
  |------------|----------------------------|-------------------|--------------|
  | **L2** | 按比例缩小权重 | 处处可导 | 权重接近零 |
  | **L1** | 固定步长向零移动 | 零点不可导 | 权重精确为零 |

#### 6.4 正则化效果对比

| 特性             | L1 正则化 (Lasso)          | L2 正则化 (Ridge)      |
| ---------------- | -------------------------- | ---------------------- |
| **惩罚项**       | $\sum \|w_j\|$             | $\sum w_j^2$           |
| **解的特性**     | 稀疏解（ 部分权重=0 ）     | 稠密解（ 权重接近 0 ） |
| **特征选择能力** | 较强                       | 较弱                   |
| **抗噪声能力**   | 较弱                       | 较强                   |
| **计算复杂度**   | 需特殊优化（ 如坐标下降 ） | 可直接求解析解         |

#### 6.5 正则化系数选择

- 通常尝试 $\lambda \in [0.001, 0.01, 0.1, 1, 10, 100]$
- 典型现象：
  - $\lambda$ 太小 → 过拟合（ 训练误差 << 验证误差 ）
  - $\lambda$ 太大 → 欠拟合（ 训练和验证误差均大 ）
