## 1. CNN（ Convolutional Neural Networks，卷积神经网络 ）

- 卷积神经网络指至少有一层卷积层的神经网络

#### 1.1 卷积层

- 卷积层对输入图像进行转换，以从中提取特征。在这种转换中，图像与卷积核进行卷积
  ![image](https://github.com/jianyi-gronk/jianyi-gronk/assets/95062803/b5da219b-192c-4a4a-b8c0-1fd269b6c41d)
- 卷积核是一个小的矩阵，其高度和宽度小于要卷积的图像。它也被称为卷积矩阵或卷积掩码。该核在图像输入的高度和宽度上滑动，并且核的点积和图像在每个空间位置处进行计算。核滑动的长度称为步幅长度（ stride ）。输出图像也称为卷积特征
- 当使用通道为 3 卷积彩色图像（ RGB 图像 ）时，过滤器的通道也必须为 3。换句话说，在卷积层中，过滤器中的通道数必须与输入图像中的通道数相同
  ![image](https://github.com/jianyi-gronk/jianyi-gronk/assets/95062803/48dd4436-a625-48d9-8099-61408310ed49)
- 当我们想使用卷积从一个图像中提取多个特征时，我们可以使用多个过滤器而不是仅使用一个。在这种情况下，所有卷积核的大小必须相同。输入图像和输出图像的卷积特征一个接一个地堆叠在一起以创建输出，因此通道数等于使用的过滤器数
  ![image](https://github.com/jianyi-gronk/jianyi-gronk/assets/95062803/f4806b26-c38e-40ed-8d1e-5b9f194ec025)
- 激活函数是卷积层的最后一个组成部分，可增加输出中的非线性。通常，在卷积层中将 ReLu 函数用作激活函数。这是一个简单卷积层的图像，其中将 6 x 6 x 3 输入图像与大小为 4 x 4 x 3 的两个过滤器以得到大小为 3 x 3 x 2 的卷积特征，对其应用激活函数以获取输出，这也称为特征图
  ![image](https://github.com/jianyi-gronk/jianyi-gronk/assets/95062803/20565953-9ab1-4b49-bf97-21029490f608)
- 在卷积过程中，图像中间区域会被多次计算，而边缘区域（ 比如下图绿色阴影部分 ）只会被卷积计算一次。参数 padding 可以在输入数据的周围添加额外的边界，目的是控制卷积层输出的大小，以及在进行卷积操作时保持输入数据边界信息，p = 1 时，即会在最外层加一圈（ 蓝色区域 ）
  ![image](https://github.com/jianyi-gronk/jianyi-gronk/assets/95062803/84cb481c-3251-4a2f-9b6b-dd65ced7ca41)
- 还可以选择是否添加偏置，每个卷积层通常包括多个卷积核，每个卷积核与一个 bias（ 偏置 ）相关联，它的作用是在卷积操作后，对每个卷积核的输出加上一个常数值（ 即偏置值 ），这样提供了模型在学习过程中的额外自由度，有助于模型更好地拟合训练数据，提高模型的表达能力和泛化能力。bias 通常不需要指定，模型会自己进行训练找到最佳值

#### 1.2 卷积核 和 过滤器

- 卷积核就是由长和宽来指定的，是一个二维的概念
- 而过滤器是是由长、宽和深度指定的，是一个三维的概念
- 通常将多个卷积核组成一个过滤器。每个卷积核用于从输入数据中提取特定的特征，而过滤器则决定了网络学习到的特征种类和数量

#### 1.3 池化层

- 池化层是可以用来减小尺寸，提高运算速度的，同样能减小噪声影响，让各特征更具有健壮性
- 池化层主要有三个超参数
  ![image](https://github.com/jianyi-gronk/jianyi-gronk/assets/95062803/7b250032-cfb5-4d4e-a2a5-b4c407a992ea)
  - f：设置滑动区域大小为 f \* f
  - s：设置步幅
  - 设置为取区域内最大值还是平均值
- 平均池化的使用曾经较为广泛，但是最近由于最大池化在实践中的表现更好，所以基本现在都是使用最大池
- 由于池化层过快地减少了数据的大小，目前的趋势是使用较小的池化区域大小，通常使用 ( f = 2, s = 2)，偶尔也能看到有人采用 (f = 3, s = 2)

#### 1.4 深度卷积神经网络（ DCNN ）

- DCNN 的基本原理是通过卷积和池化操作来提取图像中的特征，并通过全连接层进行分类或回归任务
- 在训练过程中，DCNN 通过反向传播算法不断调整权重参数，以最小化预测误差。通过大量的训练数据，DCNN 可以逐渐学习到图像中的复杂特征，并在测试阶段对未见过的图像进行准确的分类或识别

## 2. FCN（ Fully Convolutional Networks，全卷积网络 ）

- 传统 CNN 在卷积层之后会接上若干全连接层，将卷积层产生的特征图（ feature map ）映射成一个固定长度的特征向量，比如把卷积神经网络的最后一层设为 softmax 进行分类，得到整个输入图像的一个数值描述（ 概率 ）
- FCN 是用于图像语义分割的一种框架，将传统 CNN 的最后的全连接层换成了卷积层，这样网络的输出是相同大小的热力图而非类别
  ![image](https://github.com/user-attachments/assets/5b5a5e2f-0a91-4024-ace6-9f08479c8f75)
- 语义分割，本质就是按图像中物体表达的含义进行抠图
  ![image](https://github.com/user-attachments/assets/2d6f4959-f8a0-4afb-9318-5bf478cf98bd)
- 存在两个问题需要解决
  - 如何解决卷积和池化导致图像尺寸的变小
  - 经过卷积和池化的特征图太小，这意味着过多细节的丢失，即使恢复原来大小的图片也丢失了过多信息

#### 2.1 网络结构

- FCN 网络结构主要分为两个部分：全卷积部分和反卷积部分
  - 全卷积部分为一些经典的 CNN 网络（ 如 VGG，ResNet 等 ），用于提取特征
  - 反卷积部分则是通过上采样得到原尺寸的语义分割图像
- FCN 的输入可以为任意尺寸的彩色图像，输出与输入尺寸相同，通道数为 n（ 目标类别数 ）+ 1（ 背景 ），FCN 网络结构如下
  ![image](https://github.com/user-attachments/assets/3971f239-1ebd-426b-b081-7fa24154086e)

#### 2.2 上采样（ upsampling ）

- 上采样的意义在于将小尺寸的高维度特征图恢复回去，以便做像素级的预测（ pixelwise prediction ），获得每个点的分类信息（ 语义分割 ）
- 上采样方式首先将原始图像的尺寸进行放大，空出来很多需要补充的区域，然后通过一定的插值算法来计算待补充的区域，从而实现图像的放大，常用的插值算法是双线性插值和反卷积

#### 2.3 跳跃结构

- 模型前期通过卷积、池化、非线性激活函数等作用输出了特征权重图像，所以卷积池化的最后特征图（ 也叫热图， heatmap ）太小，通常会损失很多细节
- 在 FCN 中，通常将热图扩大了 32 倍
  - ![image](https://github.com/user-attachments/assets/4b169b50-0016-4083-8788-daf544e9b5b0)
- 在论文中提出了三个模型分别是 FCN-32s、FCN-16s、FCN-8s
- FCN-32s
  - 将 pool5 的输出直接上采样 32 倍恢复到原图大小，将损失了原图很多细节信息的特征图直接上采样，效果较差
- FCN-16s
  - pool5 的输出上采样 2 倍（ 采样后大小与 pool4 的输出相同 ），然后与之前 pool4 输出相加然后再直接上采样 16 倍恢复到原图大小
- FCN-8s
  - pool5 的输出上采样 2 倍，然后与之前 pool4 输出相加然后再上采样 2 倍，然后与之前 pool3 输出相加然后再直接上采样 8 倍恢复到原图大小
- 在原文中给出 3 种网络结果对比，明显可以看出效果 FCN-32s < FCN-16s < FCN-8s，即使用多层 feature 融合有利于提高分割准确性，效果如下
  ![image](https://github.com/user-attachments/assets/358c6e76-a3d7-4009-8876-e04b8d4ae921)

## 3. UNet

- UNet 模型是与 FCN 同年 2015 年提出来的，UNet 模型可以算是医学图像分割领域的领头者，其也是通过下采样获取特征图，然后再上采样还原到原图
- 由一个编码器和一个解码器组成，前者生成图像的表示，后者使用该表示来构建分割。每个空间分辨率的两个映射连接在一起(灰色箭头)，因此可以将图像的两种不同表示组合在一起
  ![image](https://github.com/user-attachments/assets/0da0cf91-8007-4309-bd37-01ea8511310f)
- 这个结构就是先对图片进行卷积和池化，在 UNet 论文中是池化 4 次，比如说一开始的图片是 224 \* 224 的，那么就会变成 112 \* 112，56 \* 56，28 \* 28，14 \* 14 四个不同尺寸的特征。然后我们对 14 \* 14 的特征图做上采样，得到 28 \* 28 的特征图，这个 28 \* 28 的特征图与之前的 28 \* 28 的特征图进行通道伤的拼接 concat，然后再对拼接之后的特征图做卷积和上采样，得到 56 \* 56 的特征图，再与之前的 56 \* 56 的特征拼接，卷积，再上采样，经过四次上采样可以得到一个与输入图像尺寸相同的 224 \* 224 的预测结果
- 需要注意，FCN 中通过相加来融合特征，而 UNet 通过通道数的拼接（ 堆叠 ），这样可以形成更厚的特征，当然这样会更佳消耗显存
- 整体来看，这个也是一个 Encoder-Decoder 的结构，前半部分就是特征提取（ Encoder ），后半部分是上采样（ Decoder ）
- 大多数医疗影像语义分割任务都会首先用 UNet 作为 baseline，为什么 UNet 在医疗图像分割种表现好
  - 医疗影像语义较为简单、结构固定。因此语义信息相比自动驾驶等较为单一，不需要去筛选过滤无用的信息。医疗影像的所有特征都很重要，因此低级特征和高级语义特征都很重要，所以 U 型结构的 skip connection 结构（ 特征拼接 ）更好派上用场
  - 医学影像的数据较少，获取难度大，数据量可能只有几百甚至不到 100，因此如果使用大型的网络例如 DeepLabv3+ 等模型，很容易过拟合。大型网络的优点是更强的图像表述能力，而较为简单、数量少的医学影像并没有那么多的内容需要表述，因此也有人发现在小数量级中，分割的 SOTA 模型与轻量的 UNet 并没有什么优势
  - 医学影像往往是多模态的。比方说 ISLES 脑梗竞赛中，官方提供了 CBF，MTT，CBV 等多中模态的数据。因此医学影像任务中，往往需要自己设计网络去提取不同的模态特征，因此轻量结构简单的 Unet 可以有更大的操作空间
  - 可解释性的重要性，由于医疗影像最终是辅助医生的临床诊断，所以网络告诉医生一个 3D 的 CT 有没有病是远远不够的，医生还要进一步的想知道，病在哪一层，在哪一层的哪个位置，语义分割出来了吗

## 4. UNet++

- UNet 存在问题，既然 UNet 每一层抓取的特征都很重要，为什么非要降四次之后才开始上采样回去呢，这个 “四” 真的适用所有场景吗
- 为了验证多深才好，于是每加一个深度就训练一个网络。实验证明不是越深越好，即不同层次特征的重要性对于不同的数据集是不一样的，并不是说设计一个原论文给出的那个四层结构，就一定对所有数据集的分割问题都最优，但是总不能把所有不同深度的 UNet 都训练一遍，太耗时间了，于是提出 UNet++
- UNet++ 是对 UNet 体系结构的改进，它有多个跳跃连接，可以抓取不同层次的特征，将它们通过特征叠加的方式整合，加入更浅的 UNet 结构，使得融合时的特征图尺度差异更小，同时也引进了很多参数，占用内存也变大
- 结构如下，采用了嵌套和密集跳过连接的网络结构，把 1 ～ 4 层的 Unet 全给连一起了，它的子集包含 1 层 UNet，2 层 UNet，以此类推
  ![image](https://github.com/user-attachments/assets/5874a725-1b9b-47d0-bac0-75041fda218f)
  - 第一个好处是不管哪个深度的特征有效，干脆都给用上，让网络自己去学习不同深度的特征的重要性
  - 第二个好处是它共享了一个特征提取器，也就是不需要训练一堆 Unet，而是只训练一个 encoder，它的不同层次的特征由不同的 decoder 路径来还原。这个 encoder 依旧可以灵活的用各种不同的 backbone 来代替

## 5. UNet3+

- UNet++ 虽然名义上通过嵌套和密集跳过连接进行了多尺度信息的利用，但是从本质上看基本都是短连接，基本上都对解码特征进行了再次处理，再加上各个连接的融合，多尺度信息的原始特征几乎没有得到特别好的利用，信号处理有些矫枉过正或是丢失
- UNet3+ 利用了全尺度的跳跃连接（ skip connection ）和深度监督（ deep supervisions ），并且 UNet3+ 的参数量明显小于 UNet++
  ![image](https://github.com/user-attachments/assets/ff1a1f76-f0a8-44ed-96e6-7ae920e56edb)
  - 全尺度的跳跃连接把来自不同尺度特征图中的高级语义与低级语义直接结合（ 当然需要必要的上采样操作 ）
  - 深度监督则从多尺度聚合的特征图中学习层次表示。虽然 UNet++ 和 UNet3+ 都用到了深度监督，但是监督的位置是完全不一样的

#### 5.1 全尺寸跳跃连接

- 下图详细说明了构造 $X_{De}^{3}$ 特征图的全过程，特征图 $X_{De}^{3}$ 的全尺寸连接主要是来自三个部分
  ![image](https://github.com/user-attachments/assets/3b0cb347-dfb3-47b8-8e1d-f9c7e1330906)
  ![image](https://github.com/user-attachments/assets/ac794506-d8b8-482d-9b1a-8e90bf08c9ef)
  - 五层叠加（ 拼接融合 ）形成 320 通道的特征图。随后再进行 320 通道的 3\*3 卷积、BN、Relu 等操作形成新的特征图 $X_{De}^{3}$，其他解码部分的特征图生成过程类似

#### 5.2 全尺寸深监督

- UNet++ 深监督部分
  - UNet++ 是对第一层的特征图进行深监督，即对全分辨率特征图进行深监督，$X_{De}^{1,1}$，$X_{De}^{1,2}$，$X_{De}^{1,3}$，$X_{De}^{1,4}$，在实际操作中 UNet++使用 1\*1 卷积分别对 $X_{De}^{1,1}$，$X_{De}^{1,2}$，$X_{De}^{1,3}$，$X_{De}^{1,4}$ 进行操作，去监督每个分支的输出
- UNet3+ 深监督部分
  - UNet3+ 全尺寸深监督是每个解码器对应一个侧输出（ side output ），通过 ground truth 进行监督。为了实现深度监控，每个解码器的最后一层被送入一个普通的 3 × 3 卷积层，然后是一个双线性上采样和一个 sigmoid 函数
  - 此处进行双线性上采样的目的我认为主要有两个：
    - 上采样是将第 2、3、4、5 层扩展成全分辨率特征图，保证与第一层相同，这也是全尺寸深监督的关键操作
    - 双线性上采样的方式可以最大限度保证上采样过程中边缘信息的完整性（ 医学图像边缘的不确定性决定要尽量保障边缘信息不丢失 ）

#### 5.3 UNet、UNet++ 和 UNet3+ 参数数量计算与比较

- 通过公式表示全尺寸跳跃连接，i 表示沿着编码的方向第 i 个下采样层，N 表示编码器个数，那么特征图 $X_{De}^{i}$ 的计算公式如下
  ![image](https://github.com/user-attachments/assets/8e55d474-0770-4c34-8878-35367f2ad1ac)
- UNet、UNet++和 UNet3+编码器的结构三者都是一样的，$X_{En}^{i}$ 都为 32 × $2^i$ 通道数，编码部分的参数都是一样多的，他们的不同主要是体现在解码部分
- UNet 解码部分
  ![image](https://github.com/user-attachments/assets/1259b4a1-0ee4-4396-b782-36fb2b2bd45f)
  - UNet 的解码部分和编码部分是对称的，因此 $X_{De}^{i}$ 都为 32 × $2^i$ 通道
- UNet++ 解码部分
  ![image](https://github.com/user-attachments/assets/982cf9ec-a46c-481d-9948-6c524244bbbb)
  - 在 UNet++ 中, 它在每一条跳跃路径上都利用了稠密卷积模块（ dense conv block ）
- UNet3+ 解码部分
  ![image](https://github.com/user-attachments/assets/fd060aa5-c4b3-4ede-a173-840dfa06eca7)
  - 在 UNet3+中, 每一个解码器由 N 个尺度连接所成, 所以产生 64 × N 通道
- 通过公式可以看出，虽然从网络结构上看，UNet 最为清晰明了，貌似参数应该更少，其实并不是这样。在保障相同的编码部分的前提下，它们三者中 UNet3+ 的参数量最少，其次才是 UNet，UNet++ 的参数量是最多的（ 结构也最复杂 ）
