## 1. FCN（ Fully Convolutional Networks，全卷积网络 ）

- 语义分割，本质就是按图像中物体表达的含义进行抠图，而 FCN 就是用于图像语义分割的框架
  ![image](https://github.com/user-attachments/assets/2d6f4959-f8a0-4afb-9318-5bf478cf98bd)

#### 1.1 与传统 CNN 对比

- 传统 CNN
  - 在卷积层之后会接上若干全连接层，将卷积层产生的 特征图 映射成固定长度的特征向量
  - 比如把卷积神经网络的最后一层设为 softmax 进行分类，得到整个输入图像的一个数值描述（ 概率 ）
  - 局限性
    - 全连接层参数量巨大，如 7×7×512 特征图展平后 → 25088 维 → 1000 类，需要 25M 参数
    - 固定输入尺寸要求，空间信息完全丢失
- FCN
  - 将传统 CNN 的最后的全连接层换成了卷积层，这样网络的输出是相同大小的热力图而非数值
    ![image](https://github.com/user-attachments/assets/5b5a5e2f-0a91-4024-ace6-9f08479c8f75)
  - 优势
    - 全卷积结构，参数量少
    - 支持任意尺寸输入，同时保留空间信息（ 输出每个像素的类别概率 ）
  - 存在两个问题需要解决
    - 如何解决卷积和池化导致图像尺寸的变小
    - 经过卷积和池化的特征图太小，这意味着过多细节的丢失，即使恢复原来大小的图片也丢失了过多信息

#### 1.2 网络结构

- FCN 网络结构分为 编码器 和 解码器，实现端到端训练
- 编码器（ 全卷积部分 ）
  - 核心：采用经典 CNN 骨干网络（ 如 VGG16、ResNet 等 ），通过卷积和池化提取多级特征
  - 输入：任意尺寸彩色图像，如 $H \times W \times 3$
  - 输出：多级特征图（ 如 pool3、pool4、pool5 ），尺寸逐步缩小
- 解码器（ 上采样部分 ）
  - 核心：通过 上采样 和 跳跃连接 得到原尺寸的语义分割图像
  - 输入：编码器输出的多级特征图
  - 输出：与输入尺寸相同的热力图（ $H \times W \times (N+1)$ ），即通道数为 N（ 目标类别数 ）+ 1（ 背景 ）
- 损失函数
  - 逐像素交叉熵损失是 FCN 的标准损失函数，支持端到端训练  
    $$\mathcal{L} = -\sum_{i,j} \sum_{k=1}^{N+1} y_{i,j,k} \log(\hat{y}_{i,j,k})$$
    - 其中，$y*{i,j,k}$ 是像素 $(i,j)$ 的真实类别标签，$\hat{y}*{i,j,k}$ 是预测概率
- 网络结构图
  ![image](https://github.com/user-attachments/assets/3971f239-1ebd-426b-b081-7fa24154086e)

#### 1.3 上采样（ upsampling ）

- 上采样的意义在于将小尺寸的高维度特征图恢复回去，以便做像素级的预测，获得每个点的分类信息（ 语义分割 ）
- 上采样方式首先将原始图像的尺寸进行放大，空出来很多需要补充的区域，然后通过一定的插值算法来计算待补充的区域，从而实现图像的放大
- 常用的上采样方法
  - **插值方法**：双线性插值、最近邻插值，简单高效但不可学习
  - **转置卷积**：使用可学习权重进行上采样，步幅控制放大倍数

#### 1.4 跳跃结构

- 模型前期通过卷积、池化、非线性激活函数等作用输出了特征权重图像，所以卷积池化的最后特征图（ 也叫热图， heatmap ）太小，通常会损失很多细节
- 在 FCN 中，通常将热图扩大了 32 倍
  - ![image](https://github.com/user-attachments/assets/4b169b50-0016-4083-8788-daf544e9b5b0)
- 在论文中提出了三个模型分别是 FCN-32s、FCN-16s、FCN-8s
- FCN-32s
  - 将 pool5 的输出直接上采样 32 倍恢复到原图大小，将损失了原图很多细节信息的特征图直接上采样，效果较差
- FCN-16s
  - pool5 的输出上采样 2 倍（ 采样后大小与 pool4 的输出相同 ），然后与之前 pool4 输出相加然后再直接上采样 16 倍恢复到原图大小
- FCN-8s
  - pool5 的输出上采样 2 倍，然后与之前 pool4 输出相加然后再上采样 2 倍，然后与之前 pool3 输出相加然后再直接上采样 8 倍恢复到原图大小
- 在原文中给出 3 种网络结果对比，明显可以看出效果 FCN-32s < FCN-16s < FCN-8s，即使用多层 feature 融合有利于提高分割准确性，效果如下
  ![image](https://github.com/user-attachments/assets/358c6e76-a3d7-4009-8876-e04b8d4ae921)
