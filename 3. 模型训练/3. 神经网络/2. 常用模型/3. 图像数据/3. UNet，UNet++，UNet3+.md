## 1. UNet

- UNet 模型是与 FCN 同年 2015 年提出来的，网络支持端到端训练，可以算是医学图像分割领域的领头者
- 命名由来：网络结构呈 U 形、对称设计，左侧为编码器（ 收缩路径 ），右侧为解码器（ 扩展路径 ），通过 跳跃连接 桥接两者
  ![image](https://github.com/user-attachments/assets/0da0cf91-8007-4309-bd37-01ea8511310f)

#### 1.1 与 FCN 的对比

- 相似点
  - 两者都采用 Encoder-Decoder 结构，通过下采样提取特征，上采样恢复分辨率，并使用跳跃连接融合多级特征
- 不同点
  - FCN 使用 相加 融合特征
    - 适合一般语义分割
  - UNet 使用 通道拼接 融合特征
    - 形成更厚的特征图，保留更多细节信息，但会消耗更多显存
    - 更注重低级特征的保留，适用于数据量小、细节丰富的医疗图像

#### 1.2 编码器（ 收缩路径 ）

- 核心
  - 重复应用卷积和最大池化操作，提取多尺度特征
- 典型结构（ 原论文 ）
  - 输入图像尺寸为 572×572×1（ 灰度医疗图像 ）
  - 经过 4 次下采样，每次 2×2 最大池化，步幅 2
- 示例过程（ 假设输入 224×224×3 ）
  - 初始块：两个 3×3 卷积 + ReLU，通道数翻倍（ 例如从 3 到 64 ）
  - 下采样 4 次：尺寸依次变为 112×112、56×56、28×28、14×14，通道数逐步增加 64 → 128 → 256 → 512 → 1024
- 输出
  - 多级特征图，底部为高语义、低分辨率的瓶颈特征

#### 1.3 解码器（ 扩展路径 ）

- 核心
  - 通过 上采样 恢复分辨率，并通过 跳跃连接 融合编码器的对应特征
- 上采样
  - 主要使用转置卷积，步幅 2，实现 2 倍放大
  - 优点
    - 可学习参数，优化细节重建
    - 相比双线性插值，更好保留语义信息
- 跳转连接
  - 下采样导致细节丢失，跳跃连接通过拼接 浅层（ 高分辨率、细节丰富 ）和 深层（ 高语义 ）特征，实现信息互补
  - 实现
    - 每个解码器层与对应编码器层拼接（ 通道维堆叠 ），然后卷积融合
    - 注意，拼接前需裁剪编码器特征，以匹配上采样后的尺寸（ 原论文中由于 padding 导致边缘差异 ）
  - 优势
    - 相比 FCN 的相加，拼接保留原始特征维度，提升分割边界精度
- 示例过程
  - 从瓶颈 14×14×1024 开始，上采样（ 转置卷积 ）到 28×28×512
  - 与编码器的 28×28×512 特征拼接，得到 28×28×1024
  - 应用两个 3×3 卷积 + ReLU，减少通道数（ 例如到 512 ）
  - 重复上采样、拼接、卷积过程 4 次，最终输出 224×224×N（ N 为类别数 ）
- 最终层
  - 1×1 卷积 + softmax 或 sigmoid，生成像素级概率图

#### 1.4 损失函数

- 常用逐像素交叉熵损失（ 类似于 FCN ）
  $$ \mathcal{L} = -\sum*{i,j} \sum*{k=1}^{N} y*{i,j,k} \log(\hat{y}*{i,j,k}) $$
- 在医疗分割中，常结合 Dice 损失以处理类别不平衡
  $$ \text{Dice} = \frac{2 |X \cap Y|}{|X| + |Y|} $$
  - 其中 $X$ 和 $Y$ 分别为预测和真实分割区域

#### 1.5 医疗图像分割场景

- 大多数医疗影像语义分割任务都会首先用 UNet 作为 baseline，原因包括
  - 语义简单、结构固定
    - 医疗图像（ 如 CT、MRI ）语义单一，所有特征（ 如边缘、纹理 ）都很重要，无需过滤无关内容（ 如自动驾驶中的背景干扰 ）
    - U 型结构的跳跃连接能有效融合低级细节和高语义信息，适合低级特征和高级语义特征都很重要的场景
  - 数据量小
    - 大型网络的优点是更强的图像表述能力，而较为简单、数量少的医学影像并没有那么多的内容需要表述，因此分割的 SOTA 模型相比轻量的 UNet 并没有什么优势
    - 医学数据获取难，样本常少于 1000。因此如果使用大型的网络例如 DeepLabv3+ 等模型，很容易过拟合，而 UNet 结构轻量（ 无全连接层 ），不易过拟合
  - 多模态支持
    - 医学影像往往是多模态的，比方说 ISLES 脑梗竞赛中，官方提供了 CBF，MTT，CBV 等多种模态的数据
    - UNet 的轻量简单结构便于自定义修改，便于自己设计网络去提取不同的模态特征，如多输入分支提取不同模态特征
  - 可解释性强
    - 输出像素级分割，提供临床诊断所需的空间细节，便于医生临床诊断（ 例如 3D CT 中定位病因的层级位置 ），这远超分类任务
- 局限性
  - 对大分辨率图像显存消耗大，后续变体（ 如 UNet++、Attention UNet ）会进一步优化

## 2. UNet++

- UNet 存在问题，既然 UNet 每一层抓取的特征都很重要，为什么非要降四次之后才开始上采样回去呢，这个 “四” 真的适用所有场景吗
- 为了验证多深才好，于是每加一个深度就训练一个网络。实验证明不是越深越好，即不同层次特征的重要性对于不同的数据集是不一样的，并不是说设计一个原论文给出的那个四层结构，就一定对所有数据集的分割问题都最优，但是总不能把所有不同深度的 UNet 都训练一遍，太耗时间了，于是提出 UNet++
- UNet++ 是对 UNet 体系结构的改进，它有多个跳跃连接，可以抓取不同层次的特征，将它们通过特征叠加的方式整合，加入更浅的 UNet 结构，使得融合时的特征图尺度差异更小，同时也引进了很多参数，占用内存也变大
- 结构如下，采用了嵌套和密集跳过连接的网络结构，把 1 ～ 4 层的 Unet 全给连一起了，它的子集包含 1 层 UNet，2 层 UNet，以此类推
  ![image](https://github.com/user-attachments/assets/5874a725-1b9b-47d0-bac0-75041fda218f)
  - 第一个好处是不管哪个深度的特征有效，干脆都给用上，让网络自己去学习不同深度的特征的重要性
  - 第二个好处是它共享了一个特征提取器，也就是不需要训练一堆 Unet，而是只训练一个 encoder，它的不同层次的特征由不同的 decoder 路径来还原。这个 encoder 依旧可以灵活的用各种不同的 backbone 来代替

## 3. UNet3+

- UNet++ 虽然名义上通过嵌套和密集跳过连接进行了多尺度信息的利用，但是从本质上看基本都是短连接，基本上都对解码特征进行了再次处理，再加上各个连接的融合，多尺度信息的原始特征几乎没有得到特别好的利用，信号处理有些矫枉过正或是丢失
- UNet3+ 利用了全尺度的跳跃连接（ skip connection ）和深度监督（ deep supervisions ），并且 UNet3+ 的参数量明显小于 UNet++
  ![image](https://github.com/user-attachments/assets/ff1a1f76-f0a8-44ed-96e6-7ae920e56edb)
  - 全尺度的跳跃连接把来自不同尺度特征图中的高级语义与低级语义直接结合（ 当然需要必要的上采样操作 ）
  - 深度监督则从多尺度聚合的特征图中学习层次表示。虽然 UNet++ 和 UNet3+ 都用到了深度监督，但是监督的位置是完全不一样的

#### 3.1 全尺寸跳跃连接

- 下图详细说明了构造 $X_{De}^{3}$ 特征图的全过程，特征图 $X_{De}^{3}$ 的全尺寸连接主要是来自三个部分
  ![image](https://github.com/user-attachments/assets/3b0cb347-dfb3-47b8-8e1d-f9c7e1330906)
  ![image](https://github.com/user-attachments/assets/ac794506-d8b8-482d-9b1a-8e90bf08c9ef)
  - 五层叠加（ 拼接融合 ）形成 320 通道的特征图。随后再进行 320 通道的 3\*3 卷积、BN、Relu 等操作形成新的特征图 $X_{De}^{3}$，其他解码部分的特征图生成过程类似

#### 3.2 全尺寸深监督

- UNet++ 深监督部分
  - UNet++ 是对第一层的特征图进行深监督，即对全分辨率特征图进行深监督，$X_{De}^{1,1}$，$X_{De}^{1,2}$，$X_{De}^{1,3}$，$X_{De}^{1,4}$，在实际操作中 UNet++使用 1\*1 卷积分别对 $X_{De}^{1,1}$，$X_{De}^{1,2}$，$X_{De}^{1,3}$，$X_{De}^{1,4}$ 进行操作，去监督每个分支的输出
- UNet3+ 深监督部分
  - UNet3+ 全尺寸深监督是每个解码器对应一个侧输出（ side output ），通过 ground truth 进行监督。为了实现深度监控，每个解码器的最后一层被送入一个普通的 3 × 3 卷积层，然后是一个双线性上采样和一个 sigmoid 函数
  - 此处进行双线性上采样的目的我认为主要有两个：
    - 上采样是将第 2、3、4、5 层扩展成全分辨率特征图，保证与第一层相同，这也是全尺寸深监督的关键操作
    - 双线性上采样的方式可以最大限度保证上采样过程中边缘信息的完整性（ 医学图像边缘的不确定性决定要尽量保障边缘信息不丢失 ）

#### 3.3 UNet、UNet++ 和 UNet3+ 参数数量计算与比较

- 通过公式表示全尺寸跳跃连接，i 表示沿着编码的方向第 i 个下采样层，N 表示编码器个数，那么特征图 $X_{De}^{i}$ 的计算公式如下
  ![image](https://github.com/user-attachments/assets/8e55d474-0770-4c34-8878-35367f2ad1ac)
- UNet、UNet++和 UNet3+编码器的结构三者都是一样的，$X_{En}^{i}$ 都为 32 × $2^i$ 通道数，编码部分的参数都是一样多的，他们的不同主要是体现在解码部分
- UNet 解码部分
  ![image](https://github.com/user-attachments/assets/1259b4a1-0ee4-4396-b782-36fb2b2bd45f)
  - UNet 的解码部分和编码部分是对称的，因此 $X_{De}^{i}$ 都为 32 × $2^i$ 通道
- UNet++ 解码部分
  ![image](https://github.com/user-attachments/assets/982cf9ec-a46c-481d-9948-6c524244bbbb)
  - 在 UNet++ 中, 它在每一条跳跃路径上都利用了稠密卷积模块（ dense conv block ）
- UNet3+ 解码部分
  ![image](https://github.com/user-attachments/assets/fd060aa5-c4b3-4ede-a173-840dfa06eca7)
  - 在 UNet3+中, 每一个解码器由 N 个尺度连接所成, 所以产生 64 × N 通道
- 通过公式可以看出，虽然从网络结构上看，UNet 最为清晰明了，貌似参数应该更少，其实并不是这样。在保障相同的编码部分的前提下，它们三者中 UNet3+ 的参数量最少，其次才是 UNet，UNet++ 的参数量是最多的（ 结构也最复杂 ）
