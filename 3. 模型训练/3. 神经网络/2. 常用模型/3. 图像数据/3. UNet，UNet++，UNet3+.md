## 1. UNet

- UNet 模型是与 FCN 同年 2015 年提出来的，UNet 模型可以算是医学图像分割领域的领头者，其也是通过下采样获取特征图，然后再上采样还原到原图
- 由一个编码器和一个解码器组成，前者生成图像的表示，后者使用该表示来构建分割。每个空间分辨率的两个映射连接在一起（ 灰色箭头 ），因此可以将图像的两种不同表示组合在一起
  ![image](https://github.com/user-attachments/assets/0da0cf91-8007-4309-bd37-01ea8511310f)
- 这个结构就是先对图片进行卷积和池化，在 UNet 论文中是池化 4 次，比如说一开始的图片是 224 \* 224 的，那么就会变成 112 \* 112，56 \* 56，28 \* 28，14 \* 14 四个不同尺寸的特征。然后我们对 14 \* 14 的特征图做上采样，得到 28 \* 28 的特征图，这个 28 \* 28 的特征图与之前的 28 \* 28 的特征图进行通道伤的拼接 concat，然后再对拼接之后的特征图做卷积和上采样，得到 56 \* 56 的特征图，再与之前的 56 \* 56 的特征拼接，卷积，再上采样，经过四次上采样可以得到一个与输入图像尺寸相同的 224 \* 224 的预测结果
- 需要注意，FCN 中通过相加来融合特征，而 UNet 通过通道数的拼接（ 堆叠 ），这样可以形成更厚的特征，当然这样会更佳消耗显存
- 整体来看，这个也是一个 Encoder-Decoder 的结构，前半部分就是特征提取（ Encoder ），后半部分是上采样（ Decoder ）
- 大多数医疗影像语义分割任务都会首先用 UNet 作为 baseline，为什么 UNet 在医疗图像分割种表现好
  - 医疗影像语义较为简单、结构固定。因此语义信息相比自动驾驶等较为单一，不需要去筛选过滤无用的信息。医疗影像的所有特征都很重要，因此低级特征和高级语义特征都很重要，所以 U 型结构的 skip connection 结构（ 特征拼接 ）更好派上用场
  - 医学影像的数据较少，获取难度大，数据量可能只有几百甚至不到 100，因此如果使用大型的网络例如 DeepLabv3+ 等模型，很容易过拟合。大型网络的优点是更强的图像表述能力，而较为简单、数量少的医学影像并没有那么多的内容需要表述，因此也有人发现在小数量级中，分割的 SOTA 模型与轻量的 UNet 并没有什么优势
  - 医学影像往往是多模态的。比方说 ISLES 脑梗竞赛中，官方提供了 CBF，MTT，CBV 等多中模态的数据。因此医学影像任务中，往往需要自己设计网络去提取不同的模态特征，因此轻量结构简单的 Unet 可以有更大的操作空间
  - 可解释性的重要性，由于医疗影像最终是辅助医生的临床诊断，所以网络告诉医生一个 3D 的 CT 有没有病是远远不够的，医生还要进一步的想知道，病在哪一层，在哪一层的哪个位置，语义分割出来了吗

## 2. UNet++

- UNet 存在问题，既然 UNet 每一层抓取的特征都很重要，为什么非要降四次之后才开始上采样回去呢，这个 “四” 真的适用所有场景吗
- 为了验证多深才好，于是每加一个深度就训练一个网络。实验证明不是越深越好，即不同层次特征的重要性对于不同的数据集是不一样的，并不是说设计一个原论文给出的那个四层结构，就一定对所有数据集的分割问题都最优，但是总不能把所有不同深度的 UNet 都训练一遍，太耗时间了，于是提出 UNet++
- UNet++ 是对 UNet 体系结构的改进，它有多个跳跃连接，可以抓取不同层次的特征，将它们通过特征叠加的方式整合，加入更浅的 UNet 结构，使得融合时的特征图尺度差异更小，同时也引进了很多参数，占用内存也变大
- 结构如下，采用了嵌套和密集跳过连接的网络结构，把 1 ～ 4 层的 Unet 全给连一起了，它的子集包含 1 层 UNet，2 层 UNet，以此类推
  ![image](https://github.com/user-attachments/assets/5874a725-1b9b-47d0-bac0-75041fda218f)
  - 第一个好处是不管哪个深度的特征有效，干脆都给用上，让网络自己去学习不同深度的特征的重要性
  - 第二个好处是它共享了一个特征提取器，也就是不需要训练一堆 Unet，而是只训练一个 encoder，它的不同层次的特征由不同的 decoder 路径来还原。这个 encoder 依旧可以灵活的用各种不同的 backbone 来代替

## 3. UNet3+

- UNet++ 虽然名义上通过嵌套和密集跳过连接进行了多尺度信息的利用，但是从本质上看基本都是短连接，基本上都对解码特征进行了再次处理，再加上各个连接的融合，多尺度信息的原始特征几乎没有得到特别好的利用，信号处理有些矫枉过正或是丢失
- UNet3+ 利用了全尺度的跳跃连接（ skip connection ）和深度监督（ deep supervisions ），并且 UNet3+ 的参数量明显小于 UNet++
  ![image](https://github.com/user-attachments/assets/ff1a1f76-f0a8-44ed-96e6-7ae920e56edb)
  - 全尺度的跳跃连接把来自不同尺度特征图中的高级语义与低级语义直接结合（ 当然需要必要的上采样操作 ）
  - 深度监督则从多尺度聚合的特征图中学习层次表示。虽然 UNet++ 和 UNet3+ 都用到了深度监督，但是监督的位置是完全不一样的

#### 3.1 全尺寸跳跃连接

- 下图详细说明了构造 $X_{De}^{3}$ 特征图的全过程，特征图 $X_{De}^{3}$ 的全尺寸连接主要是来自三个部分
  ![image](https://github.com/user-attachments/assets/3b0cb347-dfb3-47b8-8e1d-f9c7e1330906)
  ![image](https://github.com/user-attachments/assets/ac794506-d8b8-482d-9b1a-8e90bf08c9ef)
  - 五层叠加（ 拼接融合 ）形成 320 通道的特征图。随后再进行 320 通道的 3\*3 卷积、BN、Relu 等操作形成新的特征图 $X_{De}^{3}$，其他解码部分的特征图生成过程类似

#### 3.2 全尺寸深监督

- UNet++ 深监督部分
  - UNet++ 是对第一层的特征图进行深监督，即对全分辨率特征图进行深监督，$X_{De}^{1,1}$，$X_{De}^{1,2}$，$X_{De}^{1,3}$，$X_{De}^{1,4}$，在实际操作中 UNet++使用 1\*1 卷积分别对 $X_{De}^{1,1}$，$X_{De}^{1,2}$，$X_{De}^{1,3}$，$X_{De}^{1,4}$ 进行操作，去监督每个分支的输出
- UNet3+ 深监督部分
  - UNet3+ 全尺寸深监督是每个解码器对应一个侧输出（ side output ），通过 ground truth 进行监督。为了实现深度监控，每个解码器的最后一层被送入一个普通的 3 × 3 卷积层，然后是一个双线性上采样和一个 sigmoid 函数
  - 此处进行双线性上采样的目的我认为主要有两个：
    - 上采样是将第 2、3、4、5 层扩展成全分辨率特征图，保证与第一层相同，这也是全尺寸深监督的关键操作
    - 双线性上采样的方式可以最大限度保证上采样过程中边缘信息的完整性（ 医学图像边缘的不确定性决定要尽量保障边缘信息不丢失 ）

#### 3.3 UNet、UNet++ 和 UNet3+ 参数数量计算与比较

- 通过公式表示全尺寸跳跃连接，i 表示沿着编码的方向第 i 个下采样层，N 表示编码器个数，那么特征图 $X_{De}^{i}$ 的计算公式如下
  ![image](https://github.com/user-attachments/assets/8e55d474-0770-4c34-8878-35367f2ad1ac)
- UNet、UNet++和 UNet3+编码器的结构三者都是一样的，$X_{En}^{i}$ 都为 32 × $2^i$ 通道数，编码部分的参数都是一样多的，他们的不同主要是体现在解码部分
- UNet 解码部分
  ![image](https://github.com/user-attachments/assets/1259b4a1-0ee4-4396-b782-36fb2b2bd45f)
  - UNet 的解码部分和编码部分是对称的，因此 $X_{De}^{i}$ 都为 32 × $2^i$ 通道
- UNet++ 解码部分
  ![image](https://github.com/user-attachments/assets/982cf9ec-a46c-481d-9948-6c524244bbbb)
  - 在 UNet++ 中, 它在每一条跳跃路径上都利用了稠密卷积模块（ dense conv block ）
- UNet3+ 解码部分
  ![image](https://github.com/user-attachments/assets/fd060aa5-c4b3-4ede-a173-840dfa06eca7)
  - 在 UNet3+中, 每一个解码器由 N 个尺度连接所成, 所以产生 64 × N 通道
- 通过公式可以看出，虽然从网络结构上看，UNet 最为清晰明了，貌似参数应该更少，其实并不是这样。在保障相同的编码部分的前提下，它们三者中 UNet3+ 的参数量最少，其次才是 UNet，UNet++ 的参数量是最多的（ 结构也最复杂 ）
