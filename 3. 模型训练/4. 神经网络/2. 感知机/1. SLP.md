## 1. 基本概念

- SLP 是最简单的前馈神经网络，**结构只有 一个输入层 和 一个输出层**
  - 输入层：$n$ 个 **输入节点**，对应 $n$ 个特征
    $$\mathbf{x} = [x_1, x_2, \dots, x_n]^T$$
  - 输出层：$k$ 个 **神经元**，对应 $k$ 类分类
- 简单介绍下 神经元 和 输入节点
  - 神经元
    - 先接受来自前一层所有节点的输出
    - 进行计算（ 权重和偏置项 ）得到函数结果值
    - 然后通过激活函数进行处理
    - 最终得到神经元的输出值
  - 输入节点
    - 仅被动传递原始数据（ 无计算，无激活函数 ），直接把输入的特征值传给下一层

## 2. 输出层计算

- 基本公式
  $$z = \mathbf{w}^T \mathbf{x} + b = \sum_{i=1}^{n} w_i x_i + b$$
  - 权重向量：$\mathbf{w} = [w_1, w_2, \dots, w_n]^T$
  - 偏置项：$b$
- 增广表示法
  - 添加虚拟输入 $x_0 = 1$
    $$\mathbf{x'} = [1, x_1, x_2, \dots, x_n]^T$$
  - 合并偏置到权重向量，作为 $w_0$
    $$\mathbf{w'} = [b, w_1, w_2, \dots, w_n]^T$$
  - 修正后的等价公式
    $$z = \mathbf{w'}^T \mathbf{x'} = \sum_{i=0}^{n} w'_i x'_i = \sum_{i=1}^{n} w_i x_i + b$$

## 3. 输出层激活函数

- 阶跃函数（ 二分类，单个输出神经元 ）
  $$
    f(z) = \begin{cases}
      1 & \text{if } z \geq 0 \\
      -1 & \text{otherwise} \\
    \end{cases}
  $$
- Softmax 函数（ 多分类，K 个输出神经元 ）
  - 每个神经元有独立权重
    $$z_k = \mathbf{w'}_k^T \mathbf{x'} \quad (k = 1,2,\dots,K)$$
  - Softmax 函数（ 概率归一化 ）
    $$f(z_k) = \frac{e^{z_k}}{\sum_{j=1}^{K} e^{z_j}}$$
  - 满足：
    $$\sum_{k=1}^{K} f(z_k) = 1 \quad \text{且} \quad 0 < f(z_k) < 1$$
  - 预测类别：
    $$\hat{y} = \arg\max_{k} f(z_k)$$

## 4. 训练算法

- **线性决策边界**，即在 $n$ 维空间中的超平面
  - 二分类
    $$\mathbf{w}^T \mathbf{x} + b = 0$$
  - 多分类（ 类别 $k$ 和 $j$ 的边界 ）
    $$(\mathbf{w}_k - \mathbf{w}_j)^T \mathbf{x} + (b_k - b_j) = 0$$
- 损失函数：误分类点到决策边界的距离
  $$
  L(\mathbf{w}, b) = -\sum_{x_i \in M} y_i (\mathbf{w}^T \mathbf{x}_i + b)
  $$
  - 其中 $M$ 是误分类样本集
- 权重更新
  $$
  \mathbf{w} \leftarrow \mathbf{w} + \eta y_i \mathbf{x}_i \\
  b \leftarrow b + \eta y_i
  $$
  其中 $\eta$ 是学习率，$(x_i, y_i)$ 是误分类样本

## 5. 收敛性

- 感知机收敛定理：若训练数据线性可分，算法在有限步内收敛
- 局限性：
  - 只能解决线性可分问题（ 如 AND, OR ）
  - 无法解决非线性问题（ 如 XOR ）
