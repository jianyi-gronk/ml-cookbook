- 基本上能在 [sklean.metrics](https://scikit-learn.org/stable/api/sklearn.metrics.html) 中找到对应的评估方法 API

## 1. 分类任务

- 存在四个常用变量
  - True Positive（ 真正, TP ）：将正类预测为正类数
  - True Negative（ 真负, TN ）：将负类预测为负类数
  - False Positive（ 假正, FP ）：将负类预测为正类数，即误报
  - False Negative（ 假负, FN ）：将正类预测为负类数，即漏报

#### 1.1 准确率（ Accuracy ）

- 定义：**预测正确的样本占总样本的比例**
- 公式：Accuracy = (TP + TN) / (TP + TN + FP + FN)
- 适用场景：**类别平衡且误判成本相近的场景**（ 如简单图像分类 ）
- 局限性：
  - **无法处理 倾斜数据集，即 数据不平衡 的情况**（ 如欺诈检测 ）
  - 一个极端例子，比如说现在想预测人有没有生病，有 1000 个测试集数据，995 个没生病，5 个生病了，那么我全预测没生病的话，错误率是 0.5%，但是我可能自己训练的模型的错误率有 1%，那么我们也不能说这个错误率 1% 的模型差于 0.5% 错误率的模型，因为这个 0.5% 错误率的模型的预测结果是没有意义的
  - **精确率 和 召回率 就是用来处理倾斜数据集的**，如果在上面的例子中，全部预测没有生病，那么精确率和召回率都是 0，具体细节如下

#### 1.2 精确率（ Precision ）

- 定义：预测为正类的样本中实际为正类的比例，即 **衡量模型预测正类的可信度**（ 这里正类通常指很少的那部分 ）
- 公式：Precision = TP / (TP + FP)
- 适用场景：**需控制误报的场景，但对漏报不是特别敏感**（ 如垃圾邮件过滤、癌症筛查 ）

#### 1.3 召回率（ Recall / Sensitivity ）

- 定义：实际为正类的样本中被正确预测的比例，即 **衡量模型捕捉正类的全面性**（ 这里正类通常指很少的那部分 ）
- 公式：Recall = TP / (TP + FN)
- 适用场景：**需减少漏报的场景，但对误报不是特别敏感**（ 如医疗诊断、地震预警 ）

#### 1.4 F1 分数（ F1-Score ）

- 背景：通常 **精确率 和 召回率 是互斥的**
  - 降低分类阈值（ 更宽松 ）→ 更多样本被预测为正 → 召回率 ↑，但精确率 ↓
  - 提高分类阈值（ 更严格 ）→ 更少样本被预测为正 → 精确率 ↑，但召回率 ↓
- 定义：**精确率和召回率的调和平均值**
- 公式：F1 = 2 \* (Precision \* Recall) / (Precision + Recall)
- 适用场景：能用于倾斜数据集，对于并不倾向 误报 或 漏报 的，需要平衡精确率和召回率（ 如信息检索、推荐系统 ）

#### 1.5 AUC-ROC 曲线

- 背景：在 **输出概率** 的分类模型中，**分类阈值** 对模型性能评估影响很大
  - **分类阈值是一个用于将预测概率转换为具体类别标签的临界值**，当模型预测样本为正类的概率大于等于分类阈值时，将样本分类为正类
  - 降低分类阈值，会使更多的样本被预测为正类，通常会导致召回率上升，精确率下降；提高分类阈值，会使更少的样本被预测为正类，通常会导致精确率上升，召回率下降
- 定义：
  - ROC 曲线就是在不同的分类阈值下，绘制真正率（ TPR ）和假正率（ FPR ）的关系曲线
  - AUC 则是该曲线下的面积，用于综合评估模型在不同分类阈值下的性能
- 适用场景：也是用于倾斜数据集，且需综合考虑不同阈值决策的场景

#### 1.6 对数损失（ Log Loss ）

- 背景：之前的方法都关注预测的类别是否准确，而缺少方法 **衡量模型输出的这些概率与真实标签之间的差异程度**
- 定义：对数损失不仅仅关注模型分类的对错，更关注模型对自己预测的 “自信程度”，**当模型做出错误的预测且对该预测非常 “自信” 时（ 即预测概率高 ），对数损失会给予较大的惩罚**
- 公式：
  - 对数损失是对每个样本的损失进行计算后取平均值得到的
  - 对于二分类问题
    - 假设样本的真实标签为 y（ 取值为 0 或 1 ），模型预测该样本为正类（ 标签为 1 ）的概率为 p
    - 那么单个样本的对数损失计算公式为：
      - 当 y = 1 时，损失为 -log(p)
      - 当 y = 0 时，损失为 -log(1 - p)
    - 综合起来，单个样本的对数损失公式为 -[y * log(p) + (1 - y) * log(1 - p)]
- 适用场景：这个并非用于倾斜数据集，适用于需要精确概率估计，且对错误预测惩罚要求严格的场景

## 2. 回归任务

#### 2.1 解释方差（ Explained Variance ）

- 定义：衡量模型预测值与真实值的 **方差比例**，反映模型捕捉数据变化的能力
- 公式：$\text{Explained Variance} = 1 − Var(y - \hat{y}) / Var(y)$
- 取值范围：值越接近 1 表示模型越好，0 表示模型仅能预测均值
- 适用场景：评估模型对数据方差的解释能力

#### 2.2 最大误差（ Max Error ）

- 定义：预测值与真实值之间的 **最大绝对误差**
- 公式：$\text{Max Error} = \max(|y_i - \hat{y}_i|)$
- 适用场景：关注极端误差的场景

#### 2.3 中位数绝对误差（ Median AE ）

- 定义：预测值与真实值 **绝对误差的中位数**
- 公式：$\text{Median AE} = \text{median}(|y_i - \hat{y}_i|)$
- 适用场景：对异常值高度鲁棒的场景，可以屏蔽噪音干扰

#### 2.4 平均绝对误差（ Mean Absolute Error，MAE ）

- 定义：预测值与真实值 **绝对误差** 的平均值
- 公式：$\text{MAE} = \frac{1}{N} \sum |y_i - \hat{y}_i|$
- 适用场景：对异常值不敏感

#### 2.5 均方误差（ Mean Squared Error，MSE ）

- 定义：预测值与真实值 **平方误差** 的平均值
- 公式：$\text{MSE} = \frac{1}{N} \sum (y_i - \hat{y}_i)^2$
- 适用场景：关注较大误差的场景（ 较大误差被平方被放大 ）

#### 2.6 均方根误差（ Root Mean Squared Error，RMSE ）

- 定义：MSE 的平方根，与原始数据单位一致，因为 MSE 被平方后通常太大
- 公式：$\text{RMSE} = \sqrt{\text{MSE}}$
- 适用场景：和 MSE 一致

#### 2.7 R² 分数（ R² Score ）

- 定义：模型解释的方差占总方差的比例
- 公式：$R^2 = 1 - \frac{\sum (y_i - \hat{y}\_i)^2}{\sum (y_i - \bar{y})^2}$
- 取值范围：值范围为 $(-\infty, 1]$，1 表示完美预测，负值表示模型不如直接预测均值

#### 2.8 平均绝对百分比误差（ Mean Absolute Percentage Error，MAPE ）

- 定义：预测误差的 **百分比绝对值的平均值**
- 公式：$\text{MAPE} = \frac{100}{N} \sum \left| \frac{y_i - \hat{y}_i}{y_i} \right|$
- 适用场景：需直观百分比误差的场景

#### 2.9 D² 绝对误差分数（ D² Absolute Error Score ）

- 定义：基于绝对误差的 D² 分数，**衡量模型优于基线（ 中位数预测 ）的程度**
- 公式：$D^2 = 1 - \frac{\text{MAE}(y, \hat{y})}{\text{MAE}(y, \text{median}(y))}$
- 适用场景：用于对比模型与简单基线（ 如中位数预测 ）的性能

## 3. 聚类任务

- 存在两个常用概念
  - 同质性（ Homogeneity ）：每个聚类中的样本是否全部属于同一真实类别
  - 完整性（ Completeness ）：真实类别的所有样本是否被完整地分配到同一个聚类中

#### 3.1 调整兰德指数（ Adjusted Rand Score ）

- 定义：比较两个聚类结果的相似性，调整了随机分类的影响
- 公式：ARS = [RI - E(RI)] / [max(RI) - E(RI)]
- 取值范围：[-1, 1]，1 表示完全一致，0 表示随机一致
- 适用场景：对类大小不敏感的场景

#### 3.2 调整互信息（ Adjusted Mutual Information，AMI ）

- 定义：衡量两个聚类结果的互信息，调整了随机分类的影响
- 公式：AMI = [I(C1,C2) - E(I)] / [max(H(C1), H(C2)) - E(I)]
- 取值范围：范围：[-1, 1]，1 表示完全一致，0 表示随机一致
- 适用场景：适合不同大小的聚类比较

#### 3.3 归一化互信息（ Normalized Mutual Information，NMI ）

- 定义：互信息的标准化版本
- 公式：$\text{NMI} = \frac{\text{MI}(C_1, C_2)}{\sqrt{H(C_1) \cdot H(C_2)}}$
- 取值范围：[0, 1]，1 表示完全相关

#### 3.4 V-measure

- 定义：同质性和完整性的调和平均
- 公式：V = (2 \* homogeneity \* completeness) / (homogeneity + completeness)
- 取值范围：[0, 1]，1 表示完美聚类

#### 3.5 分群评估指标（ Fowlkes-Mallows，FM ）

- 定义：基于聚类和真实类的交集计算的 F1 分数
- 公式：$FM = \sqrt{(TP / (TP + FP)) * (TP / (TP + FN))}$
- 取值范围：[0, 1]，1 表示完美匹配
- 适用场景：适合类间重叠较少的情况
